#!/usr/bin/env python3
"""
æ”¹è‰¯ç‰ˆæ€§èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ - PyTorch/XLA + AWS Neuron ç’°å¢ƒã§ã®è¨ˆæ¸¬ãƒ„ãƒ¼ãƒ«

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ç™ºè¦‹ã•ã‚ŒãŸæ¸¬å®šæ‰‹æ³•ã®å•é¡Œã‚’ä¿®æ­£ã—ã€ä»¥ä¸‹ã‚’æ”¹è‰¯ã—ã¾ã—ãŸï¼š
1. ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ©Ÿèƒ½: ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã®é™¤å»
2. è©¦è¡Œå›æ•°å¢—åŠ : çµ±è¨ˆçš„å®‰å®šæ€§ã®å‘ä¸Šï¼ˆ3å›â†’10å›ï¼‰
3. åˆå›ç•°å¸¸å€¤é™¤å¤–: ç¬¬1è©¦è¡Œé™¤å¤–ã‚ªãƒ—ã‚·ãƒ§ãƒ³
4. ãƒ‡ãƒã‚¤ã‚¹å†åˆæœŸåŒ–: åˆ¶å¾¡å®Ÿé¨“æ©Ÿèƒ½
5. è©³ç´°ãƒ­ã‚°: å„è©¦è¡Œã®æ™‚é–“ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²

æ³¨æ„: ã“ã®ãƒ„ãƒ¼ãƒ«ã¯å¾“æ¥ã®ã€Œã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“æ”¯é…æ€§ã€ã®èª¤è§£ã‚’ä¿®æ­£ã—ã€
çœŸã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ï¼ˆãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ– vs å®Ÿè¡Œæ™‚é–“ï¼‰ã‚’æ¸¬å®šã—ã¾ã™ã€‚
"""

import os
import sys
import time
import json
import subprocess
import psutil
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
import statistics
import argparse

# PyTorch/XLA imports
try:
    import torch
    import torch.nn as nn
    import torch_xla
    import torch_xla.core.xla_model as xm
    from torch.func import vmap
    # æ–°ã—ã„åŒæœŸAPI
    try:
        from torch_xla import sync
        USE_NEW_SYNC_API = True
    except ImportError:
        USE_NEW_SYNC_API = False
    PYTORCH_AVAILABLE = True
except ImportError as e:
    print(f"WARNING: PyTorch/XLA not available: {e}")
    PYTORCH_AVAILABLE = False
    USE_NEW_SYNC_API = False

def xla_sync():
    """XLAåŒæœŸå‡¦ç†ï¼ˆæ–°æ—§APIå¯¾å¿œï¼‰"""
    if USE_NEW_SYNC_API:
        sync()
    else:
        xm.mark_step()

def ensure_device():
    """XLAãƒ‡ãƒã‚¤ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª"""
    if not PYTORCH_AVAILABLE:
        return None
    
    try:
        # æ–°ã—ã„APIä½¿ç”¨ã‚’è©¦è¡Œ
        try:
            from torch_xla import device as xla_device
            device = xla_device()
        except ImportError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            device = xm.xla_device()
        
        print(f"SUCCESS: XLA Device: {device}")
        return device
    except Exception as e:
        print(f"ERROR: XLA Device Error: {e}")
        return None

def device_reinitialize():
    """ãƒ‡ãƒã‚¤ã‚¹å†åˆæœŸåŒ–ï¼ˆåˆ¶å¾¡å®Ÿé¨“ç”¨ï¼‰"""
    try:
        # ãƒ‡ãƒã‚¤ã‚¹çŠ¶æ…‹ã®ã‚¯ãƒªã‚¢è©¦è¡Œ
        if USE_NEW_SYNC_API:
            torch_xla.sync()
        else:
            xm.mark_step()
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        import gc
        gc.collect()
        
        print("ğŸ”„ Device reinitialization attempted")
        time.sleep(0.1)  # çŸ­ã„å¾…æ©Ÿ
        return True
    except Exception as e:
        print(f"Warning: Device reinitialize failed: {e}")
        return False

class CompilationTimeAnalyzer:
    """æ”¹è‰¯ç‰ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“è§£æï¼ˆãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–è€ƒæ…®ï¼‰"""
    
    def __init__(self, device, warmup_iterations: int = 5, measurement_trials: int = 10, 
                 exclude_first_trial: bool = True, enable_device_reinit: bool = False):
        self.device = device
        self.warmup_iterations = warmup_iterations
        self.measurement_trials = measurement_trials
        self.exclude_first_trial = exclude_first_trial
        self.enable_device_reinit = enable_device_reinit
        self.graph_info_shown = False
        
        self.results = {
            'configuration': {
                'warmup_iterations': warmup_iterations,
                'measurement_trials': measurement_trials,
                'exclude_first_trial': exclude_first_trial,
                'enable_device_reinit': enable_device_reinit,
                'use_new_sync_api': USE_NEW_SYNC_API
            },
            'sync_time_measurements': {},
            'warmup_data': {},
            'graph_compilation_data': {},
            'execution_patterns': {},
            'theoretical_analysis': {},
            'timestamp': datetime.now().isoformat()
        }
    
    def measure_pure_sync_time(self, iterations: int = 20) -> Dict[str, float]:
        """XLAåŒæœŸã®ç´”ç²‹ãªã‚³ã‚¹ãƒˆæ¸¬å®šï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        print(f"\nPHASE 1: Enhanced XLA Synchronization Baseline Measurement")
        print(f"Measuring pure sync overhead ({iterations} iterations)")
        
        sync_times = []
        
        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        print(f"Performing {self.warmup_iterations} warmup sync operations...")
        for i in range(self.warmup_iterations):
            xla_sync()
            time.sleep(0.001)  # çŸ­ã„å¾…æ©Ÿ
        
        # å®Ÿæ¸¬å®š
        print("Starting sync time measurements...")
        for i in range(iterations):
            start = time.perf_counter()
            xla_sync()
            sync_time = time.perf_counter() - start
            sync_times.append(sync_time)
            
            if i < 5 or (i + 1) % 5 == 0:  # æœ€åˆ5å›ã¨5ã®å€æ•°ã§è¡¨ç¤º
                print(f"  Trial {i+1}/{iterations}: sync_time={sync_time:.6f}s")
        
        # çµ±è¨ˆè¨ˆç®—ï¼ˆåˆå›é™¤å¤–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        analysis_times = sync_times[1:] if self.exclude_first_trial and len(sync_times) > 1 else sync_times
        
        stats = {
            'mean': statistics.mean(analysis_times),
            'median': statistics.median(analysis_times),
            'min': min(analysis_times),
            'max': max(analysis_times),
            'stdev': statistics.stdev(analysis_times) if len(analysis_times) > 1 else 0.0
        }
        
        stats_all = {
            'mean': statistics.mean(sync_times),
            'median': statistics.median(sync_times),
            'min': min(sync_times),
            'max': max(sync_times),
            'stdev': statistics.stdev(sync_times) if len(sync_times) > 1 else 0.0
        }
        
        self.results['sync_time_measurements'] = {
            'raw_times': sync_times,
            'statistics': stats,
            'statistics_all': stats_all,
            'excluded_first': self.exclude_first_trial
        }
        
        print(f"Baseline sync time (analysis): mean={stats['mean']:.6f}s, median={stats['median']:.6f}s")
        if self.exclude_first_trial:
            print(f"Baseline sync time (all data): mean={stats_all['mean']:.6f}s, median={stats_all['median']:.6f}s")
        
        return stats
    
    def perform_warmup_execution(self, pattern_name: str, model, input_tensor, execution_func) -> Dict[str, Any]:
        """ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œï¼ˆãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–é™¤å»ï¼‰"""
        print(f"  ğŸ”¥ Performing {self.warmup_iterations} warmup executions for {pattern_name}...")
        
        warmup_times = []
        for i in range(self.warmup_iterations):
            start_time = time.perf_counter()
            execution_func(model, input_tensor)
            xla_sync()
            warmup_time = time.perf_counter() - start_time
            warmup_times.append(warmup_time)
            
            if i < 3:  # æœ€åˆ3å›è¡¨ç¤º
                print(f"    Warmup {i+1}: {warmup_time:.6f}s")
        
        return {
            'warmup_times': warmup_times,
            'warmup_mean': statistics.mean(warmup_times),
            'warmup_trend': warmup_times[-1] - warmup_times[0] if len(warmup_times) > 1 else 0
        }
    
    def create_computation_graphs(self) -> Dict[str, nn.Module]:
        """å¤šæ§˜ãªã‚µã‚¤ã‚ºã®è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
        
        # SiLU activation
        class SiLU(nn.Module):
            def __init__(self, alpha: float = 1.0):
                super().__init__()
                self.alpha = alpha
                self.activation = nn.Sigmoid()
            
            def forward(self, x):
                return self.alpha * x * self.activation(x)
        
        # è¨ˆç®—ã‚°ãƒ©ãƒ•å®šç¾©ï¼ˆåŒã˜æ§‹é€ ã‚’ç¶­æŒï¼‰
        class TinyGraph(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear = nn.Linear(64, 64)
            
            def forward(self, x):
                return torch.relu(self.linear(x))
        
        class SmallGraph(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear = nn.Linear(128, 128)
            
            def forward(self, x):
                return torch.relu(self.linear(x))
        
        class MediumGraph(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear1 = nn.Linear(256, 256)
                self.linear2 = nn.Linear(256, 256)
            
            def forward(self, x):
                x = torch.relu(self.linear1(x))
                return torch.relu(self.linear2(x))
        
        class LargeGraph(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear1 = nn.Linear(128, 128)
                self.linear2 = nn.Linear(128, 128)
                self.linear3 = nn.Linear(128, 128)
            
            def forward(self, x):
                x = torch.relu(self.linear1(x))
                x = torch.relu(self.linear2(x))
                return torch.relu(self.linear3(x))
        
        class WideGraph(nn.Module):
            def __init__(self):
                super().__init__()
                self.linear1 = nn.Linear(128, 512)
                self.linear2 = nn.Linear(512, 128)
                self.activation = SiLU()
            
            def forward(self, x):
                x = self.linear1(x)
                x = self.activation(x)
                return self.linear2(x)
        
        # ã‚°ãƒ©ãƒ•ä½œæˆã¨è©³ç´°æƒ…å ±
        def count_parameters(model):
            return sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        def count_layers(model):
            return len([m for m in model.modules() if isinstance(m, nn.Linear)])
        
        graph_classes = {
            'tiny': (TinyGraph, (64, 64), "æœ€å°: 64æ¬¡å…ƒå˜å±¤"),
            'small': (SmallGraph, (128, 128), "å°: 128æ¬¡å…ƒå˜å±¤"),
            'medium': (MediumGraph, (256, 256), "ä¸­: 256æ¬¡å…ƒ2å±¤"), 
            'large': (LargeGraph, (128, 128), "å¤§: 128æ¬¡å…ƒ3å±¤"),
            'wide': (WideGraph, (128, 512), "å¹…åºƒ: 128â†’512â†’128")
        }
        
        models = {}
        
        if not self.graph_info_shown:
            print("\nğŸ“Š è¨ˆç®—ã‚°ãƒ©ãƒ•è©³ç´°æƒ…å ±:")
            print("-" * 80)
            
            for name, (graph_class, io_dims, description) in graph_classes.items():
                model = graph_class().to(self.device)
                param_count = count_parameters(model)
                layer_count = count_layers(model)
                input_dim, hidden_dim = io_dims
                
                models[name] = model
                
                print(f"{name:12} | {description:25} | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {param_count:8,} | ãƒ¬ã‚¤ãƒ¤ãƒ¼: {layer_count} | å…¥åŠ›æ¬¡å…ƒ: {input_dim:3}")
            
            print("-" * 80)
            print(f"åˆè¨ˆ {len(models)} ç¨®é¡ã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ")
            self.graph_info_shown = True
        else:
            for name, (graph_class, io_dims, description) in graph_classes.items():
                model = graph_class().to(self.device)
                models[name] = model
        
        return models
    
    def measure_pattern_with_warmup(self, pattern_name: str, execution_func, warmup_func) -> Dict[str, Any]:
        """ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä»˜ããƒ‘ã‚¿ãƒ¼ãƒ³æ¸¬å®š"""
        print(f"\nğŸ“ˆ Pattern: {pattern_name}")
        
        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
        warmup_info = warmup_func()
        
        # å®Ÿæ¸¬å®š
        first_run_times = []
        cached_run_times = []
        detailed_timings = []
        
        print(f"  ğŸ”¬ Starting {self.measurement_trials} measurement trials...")
        
        for trial in range(self.measurement_trials):
            # åˆå›å®Ÿè¡Œã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥å®Ÿè¡Œ
            first_time, cached_time = execution_func(trial)
            
            first_run_times.append(first_time)
            cached_run_times.append(cached_time)
            
            detailed_timings.append({
                'trial': trial + 1,
                'first_run': first_time,
                'cached_run': cached_time,
                'difference': first_time - cached_time
            })
            
            if trial < 5 or (trial + 1) % 5 == 0:
                print(f"    Trial {trial+1}/{self.measurement_trials}: first={first_time:.6f}s, cached={cached_time:.6f}s")
        
        # çµ±è¨ˆåˆ†æï¼ˆåˆå›é™¤å¤–ã‚ªãƒ—ã‚·ãƒ§ãƒ³é©ç”¨ï¼‰
        analysis_first = first_run_times[1:] if self.exclude_first_trial and len(first_run_times) > 1 else first_run_times
        analysis_cached = cached_run_times[1:] if self.exclude_first_trial and len(cached_run_times) > 1 else cached_run_times
        analysis_diff = [f - c for f, c in zip(analysis_first, analysis_cached)]
        
        return {
            'first_run_times': first_run_times,
            'cached_run_times': cached_run_times,
            'compilation_times': [f - c for f, c in zip(first_run_times, cached_run_times)],
            'detailed_timings': detailed_timings,
            'warmup_data': warmup_info,
            'statistics': {
                'first_run_mean': statistics.mean(analysis_first),
                'cached_run_mean': statistics.mean(analysis_cached),
                'compilation_time_mean': statistics.mean(analysis_diff),
                'first_run_stdev': statistics.stdev(analysis_first) if len(analysis_first) > 1 else 0,
                'cached_run_stdev': statistics.stdev(analysis_cached) if len(analysis_cached) > 1 else 0,
                'excluded_first_trial': self.exclude_first_trial
            }
        }
    
    def measure_compilation_patterns(self) -> Dict[str, Any]:
        """æ”¹è‰¯ç‰ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³æ¸¬å®š"""
        print(f"\nPHASE 2: Enhanced Compilation Pattern Analysis")
        print(f"Testing with {self.measurement_trials} trials, warmup={self.warmup_iterations}")
        print(f"First trial exclusion: {'ON' if self.exclude_first_trial else 'OFF'}")
        
        models = self.create_computation_graphs()
        
        input_tensors = {
            'tiny': torch.randn(32, 64, device=self.device),
            'small': torch.randn(32, 128, device=self.device),
            'medium': torch.randn(32, 256, device=self.device),
            'large': torch.randn(32, 128, device=self.device),
            'wide': torch.randn(32, 128, device=self.device)
        }
        
        patterns = {}
        
        # é¸æŠã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã§ãƒ†ã‚¹ãƒˆ
        test_graphs = ['tiny', 'small', 'medium', 'large', 'wide']
        
        for graph_type in test_graphs:
            print(f"\nğŸ” Testing Graph Type: {graph_type.upper()}")
            input_tensor = input_tensors[graph_type]
            print(f"Input tensor shape: {input_tensor.shape}")
            
            if self.enable_device_reinit:
                device_reinitialize()
            
            # è‡ªç„¶ãªforãƒ«ãƒ¼ãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³
            def natural_loop_warmup():
                return self.perform_warmup_execution(
                    f'natural_for_loop_{graph_type}', 
                    models[graph_type], 
                    input_tensor, 
                    lambda model, inp: self._execute_natural_loop(model, inp)
                )
            
            def natural_loop_execution(trial):
                fresh_models = self.create_computation_graphs()
                x = input_tensor.clone()
                
                # åˆå›å®Ÿè¡Œ
                start_time = time.perf_counter()
                for i in range(3):
                    x = fresh_models[graph_type](x)
                xla_sync()
                first_time = time.perf_counter() - start_time
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œå®Ÿè¡Œ
                x = input_tensor.clone()
                start_time = time.perf_counter()
                for i in range(3):
                    x = fresh_models[graph_type](x)
                xla_sync()
                cached_time = time.perf_counter() - start_time
                
                return first_time, cached_time
            
            pattern_data = self.measure_pattern_with_warmup(
                f'natural_for_loop_{graph_type}',
                natural_loop_execution,
                natural_loop_warmup
            )
            
            pattern_data.update({
                'graph_count': 1,
                'sync_count': 1,
                'graph_type': graph_type,
                'input_shape': list(input_tensor.shape)
            })
            
            patterns[f'natural_for_loop_{graph_type}'] = pattern_data
        
        # Smallã‚°ãƒ©ãƒ•ã§ã®ä»–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ†ã‚¹ãƒˆ
        print(f"\nğŸ” Testing remaining patterns with SMALL graph (Enhanced)")
        small_input = input_tensors['small']
        
        if self.enable_device_reinit:
            device_reinitialize()
        
        # ä¾å­˜æ€§ã‚ã‚Šforãƒ«ãƒ¼ãƒ—
        def dependent_loop_warmup():
            return self.perform_warmup_execution(
                'dependent_for_loop_small', 
                models['small'], 
                small_input, 
                lambda model, inp: self._execute_dependent_loop(model, inp)
            )
        
        def dependent_loop_execution(trial):
            fresh_models = self.create_computation_graphs()
            
            # åˆå›å®Ÿè¡Œ
            start_time = time.perf_counter()
            results = self._execute_dependent_loop(fresh_models['small'], small_input)
            first_time = time.perf_counter() - start_time
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œå®Ÿè¡Œ
            start_time = time.perf_counter()
            results = self._execute_dependent_loop(fresh_models['small'], small_input)
            cached_time = time.perf_counter() - start_time
            
            return first_time, cached_time
        
        pattern_data = self.measure_pattern_with_warmup(
            'dependent_for_loop_small',
            dependent_loop_execution,
            dependent_loop_warmup
        )
        
        pattern_data.update({
            'graph_count': 3,
            'sync_count': 3,
            'graph_type': 'small',
            'input_shape': list(small_input.shape)
        })
        
        patterns['dependent_for_loop_small'] = pattern_data
        
        # vmap
        def vmap_warmup():
            return self.perform_warmup_execution(
                'vmap_small', 
                models['small'], 
                small_input, 
                lambda model, inp: self._execute_vmap(model, inp)
            )
        
        def vmap_execution(trial):
            fresh_models = self.create_computation_graphs()
            
            # åˆå›å®Ÿè¡Œ
            start_time = time.perf_counter()
            result = self._execute_vmap(fresh_models['small'], small_input)
            xla_sync()
            first_time = time.perf_counter() - start_time
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œå®Ÿè¡Œ
            start_time = time.perf_counter()
            result = self._execute_vmap(fresh_models['small'], small_input)
            xla_sync()
            cached_time = time.perf_counter() - start_time
            
            return first_time, cached_time
        
        pattern_data = self.measure_pattern_with_warmup(
            'vmap_small',
            vmap_execution,
            vmap_warmup
        )
        
        pattern_data.update({
            'graph_count': 1,
            'sync_count': 1,
            'graph_type': 'small',
            'input_shape': list(small_input.shape)
        })
        
        patterns['vmap_small'] = pattern_data
        
        # scan
        try:
            from torch.func import scan
            SCAN_AVAILABLE = True
            print("  Implementation: torch.func.scan")
        except ImportError:
            print("  Implementation: manual simulation")
            SCAN_AVAILABLE = False
        
        def scan_warmup():
            return self.perform_warmup_execution(
                'scan_small', 
                models['small'], 
                small_input, 
                lambda model, inp: self._execute_scan(model, inp, SCAN_AVAILABLE)
            )
        
        def scan_execution(trial):
            fresh_models = self.create_computation_graphs()
            
            # åˆå›å®Ÿè¡Œ
            start_time = time.perf_counter()
            final_carry, all_outputs = self._execute_scan(fresh_models['small'], small_input, SCAN_AVAILABLE)
            xla_sync()
            first_time = time.perf_counter() - start_time
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œå®Ÿè¡Œ
            start_time = time.perf_counter()
            final_carry, all_outputs = self._execute_scan(fresh_models['small'], small_input, SCAN_AVAILABLE)
            xla_sync()
            cached_time = time.perf_counter() - start_time
            
            return first_time, cached_time
        
        pattern_data = self.measure_pattern_with_warmup(
            'scan_small',
            scan_execution,
            scan_warmup
        )
        
        pattern_data.update({
            'graph_count': 1,
            'sync_count': 1,
            'graph_type': 'small',
            'input_shape': list(small_input.shape),
            'implementation': 'torch.func.scan' if SCAN_AVAILABLE else 'manual_simulation'
        })
        
        patterns['scan_small'] = pattern_data
        
        self.results['graph_compilation_data'] = patterns
        self.results['warmup_data'] = {k: v.get('warmup_data', {}) for k, v in patterns.items()}
        
        return patterns
    
    def _execute_natural_loop(self, model, input_tensor):
        """è‡ªç„¶ãªforãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ"""
        x = input_tensor.clone()
        for i in range(3):
            x = model(x)
        return x
    
    def _execute_dependent_loop(self, model, input_tensor):
        """ä¾å­˜æ€§ã‚ã‚Šforãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ"""
        x = input_tensor.clone()
        results = []
        for i in range(3):
            x = model(x)
            xla_sync()  # ä¸­é–“åŒæœŸ
            results.append(x.clone())
        return results
    
    def _execute_vmap(self, model, input_tensor):
        """vmapå®Ÿè¡Œ"""
        def single_layer_func(x):
            return model(x)
        
        batched_func = vmap(single_layer_func, in_dims=0)
        batch_input = input_tensor.unsqueeze(0).repeat(3, 1, 1)
        return batched_func(batch_input)
    
    def _execute_scan(self, model, input_tensor, scan_available):
        """scanå®Ÿè¡Œ"""
        if scan_available:
            from torch.func import scan
            def scan_func(carry, x):
                return model(carry), carry
            
            init_carry = input_tensor
            scan_inputs = input_tensor.unsqueeze(0).repeat(3, 1, 1)
            final_carry, all_outputs = scan(scan_func, init_carry, scan_inputs)
            return final_carry, all_outputs
        else:
            # æ‰‹å‹•scanå®Ÿè£…
            carry = input_tensor
            outputs = []
            for i in range(3):
                carry = model(carry)
                outputs.append(carry.clone())
            return carry, torch.stack(outputs, dim=0)
    
    def analyze_compilation_dominance(self) -> Dict[str, Any]:
        """æ”¹è‰¯ç‰ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ”¯é…æ€§è§£æ"""
        print("\nPHASE 3: Enhanced Performance Analysis")
        print("Analyzing measured data with device initialization consideration")
        
        sync_stats = self.results['sync_time_measurements']['statistics']
        patterns = self.results['graph_compilation_data']
        
        analysis = {}
        
        for pattern_name, data in patterns.items():
            stats = data['statistics']
            graph_count = data['graph_count']
            sync_count = data['sync_count']
            
            # å®Ÿæ¸¬åŒæœŸæ™‚é–“
            measured_sync_overhead = sync_stats['mean'] * sync_count
            
            # çœŸã®å®Ÿè¡Œæ™‚é–“ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã®å®‰å®šå€¤ï¼‰
            warmup_data = data.get('warmup_data', {})
            true_execution_time = warmup_data.get('warmup_mean', stats['cached_run_mean'])
            
            # å®Ÿæ¸¬å®Ÿè¡Œæ™‚é–“ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œæ™‚é–“ã‹ã‚‰åŒæœŸæ™‚é–“ã‚’é™¤å»ï¼‰
            measured_execution_time = stats['cached_run_mean'] - measured_sync_overhead
            
            # åˆæœŸåŒ–æ™‚é–“ï¼ˆåˆå›ç¬¬1è©¦è¡Œã®ç•°å¸¸å€¤ï¼‰
            first_trials = data['first_run_times']
            if len(first_trials) > 1:
                device_init_time = first_trials[0] - statistics.mean(first_trials[1:])
            else:
                device_init_time = 0
            
            analysis[pattern_name] = {
                'first_run_time': stats['first_run_mean'],
                'cached_run_time': stats['cached_run_mean'],
                'measured_compilation_time': stats['compilation_time_mean'],
                'measured_execution_time': measured_execution_time,
                'true_execution_time': true_execution_time,
                'measured_sync_overhead': measured_sync_overhead,
                'device_initialization_time': device_init_time,
                'compilation_ratio': stats['compilation_time_mean'] / stats['first_run_mean'] if stats['first_run_mean'] > 0 else 0,
                'execution_ratio': measured_execution_time / stats['first_run_mean'] if stats['first_run_mean'] > 0 else 0,
                'sync_ratio': measured_sync_overhead / stats['first_run_mean'] if stats['first_run_mean'] > 0 else 0,
                'cache_speedup': stats['first_run_mean'] / stats['cached_run_mean'] if stats['cached_run_mean'] > 0 else 0,
                'graphs_per_sync': graph_count / sync_count if sync_count > 0 else 0,
                'warmup_stabilization': warmup_data.get('warmup_trend', 0)
            }
        
        self.results['theoretical_analysis'] = analysis
        
        # å®Ÿæ¸¬çµæœè¡¨ç¤º
        print("\nEnhanced pattern comparison results:")
        for pattern, data in analysis.items():
            print(f"\n{pattern}:")
            print(f"  First run time: {data['first_run_time']:.6f}s")
            print(f"  Cached run time: {data['cached_run_time']:.6f}s")
            print(f"  Device init time: {data['device_initialization_time']:.6f}s")
            print(f"  True execution time: {data['true_execution_time']:.6f}s")
            print(f"  Cache speedup: {data['cache_speedup']:.2f}x")
            print(f"  Warmup trend: {data['warmup_stabilization']:.6f}s")
        
        return analysis
    
    def generate_measurement_summary(self) -> str:
        """æ”¹è‰¯ç‰ˆæ¸¬å®šçµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        
        sync_stats = self.results.get('sync_time_measurements', {}).get('statistics', {})
        patterns = self.results.get('graph_compilation_data', {})
        analysis = self.results.get('theoretical_analysis', {})
        config = self.results.get('configuration', {})
        
        summary = f"""
## æ”¹è‰¯ç‰ˆå®Ÿæ¸¬ãƒ™ãƒ¼ã‚¹è¨ˆæ¸¬çµæœã‚µãƒãƒªãƒ¼

### æ¸¬å®šè¨­å®š
- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—è©¦è¡Œ: {config.get('warmup_iterations', 0)}å›
- æ¸¬å®šè©¦è¡Œ: {config.get('measurement_trials', 0)}å›
- åˆå›è©¦è¡Œé™¤å¤–: {config.get('exclude_first_trial', False)}
- ãƒ‡ãƒã‚¤ã‚¹å†åˆæœŸåŒ–: {config.get('enable_device_reinit', False)}
- ä½¿ç”¨API: {'æ–°API (torch_xla.sync)' if config.get('use_new_sync_api', False) else 'æ—§API (xm.mark_step)'}

### åŒæœŸæ™‚é–“ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
- å¹³å‡åŒæœŸæ™‚é–“: {sync_stats.get('mean', 0):.6f}ç§’
- ä¸­å¤®å€¤: {sync_stats.get('median', 0):.6f}ç§’
- æ¨™æº–åå·®: {sync_stats.get('stdev', 0):.6f}ç§’

### ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºåˆ¥æ€§èƒ½åˆ†æï¼ˆãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–è€ƒæ…®ï¼‰
"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºåˆ¥ã«åˆ†é¡
        graph_patterns = {}
        other_patterns = {}
        
        for pattern_name, data in patterns.items():
            if 'natural_for_loop_' in pattern_name:
                graph_type = pattern_name.replace('natural_for_loop_', '')
                if graph_type not in graph_patterns:
                    graph_patterns[graph_type] = {}
                graph_patterns[graph_type]['natural_for_loop'] = (pattern_name, data, analysis.get(pattern_name, {}))
            else:
                other_patterns[pattern_name] = (data, analysis.get(pattern_name, {}))
        
        # ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºåˆ¥è¡¨ç¤º
        for graph_type in ['tiny', 'small', 'medium', 'large', 'wide']:
            if graph_type in graph_patterns:
                pattern_name, data, pattern_analysis = graph_patterns[graph_type]['natural_for_loop']
                stats = data.get('statistics', {})
                warmup_data = data.get('warmup_data', {})
                summary += f"""
#### {graph_type.upper()}ã‚°ãƒ©ãƒ• ({data.get('input_shape', [])})
  åˆå›å®Ÿè¡Œæ™‚é–“: {stats.get('first_run_mean', 0):.6f}ç§’
  ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œæ™‚é–“: {stats.get('cached_run_mean', 0):.6f}ç§’
  ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–æ™‚é–“: {pattern_analysis.get('device_initialization_time', 0):.6f}ç§’
  çœŸã®å®Ÿè¡Œæ™‚é–“: {pattern_analysis.get('true_execution_time', 0):.6f}ç§’
  ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œå¹³å‡: {warmup_data.get('warmup_mean', 0):.6f}ç§’
  ã‚­ãƒ£ãƒƒã‚·ãƒ¥é«˜é€ŸåŒ–: {pattern_analysis.get('cache_speedup', 0):.2f}å€
  ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®‰å®šåŒ–: {pattern_analysis.get('warmup_stabilization', 0):.6f}ç§’
"""
        
        summary += """
### å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥æ¯”è¼ƒï¼ˆsmallã‚°ãƒ©ãƒ•åŸºæº–ãƒ»æ”¹è‰¯ç‰ˆï¼‰
"""
        
        # ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è¡¨ç¤º
        pattern_names = {
            'dependent_for_loop_small': 'ä¾å­˜æ€§ã‚ã‚Šãƒ«ãƒ¼ãƒ—',
            'vmap_small': 'vmapä¸¦åˆ—å‡¦ç†',
            'scan_small': 'scané †æ¬¡å‡¦ç†'
        }
        
        for pattern_key, pattern_display in pattern_names.items():
            if pattern_key in other_patterns:
                data, pattern_analysis = other_patterns[pattern_key]
                stats = data.get('statistics', {})
                warmup_data = data.get('warmup_data', {})
                impl_info = f" ({data.get('implementation', '')})" if 'implementation' in data else ""
                summary += f"""
#### {pattern_display}{impl_info}
  åˆå›å®Ÿè¡Œæ™‚é–“: {stats.get('first_run_mean', 0):.6f}ç§’
  ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¾Œæ™‚é–“: {stats.get('cached_run_mean', 0):.6f}ç§’
  ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–æ™‚é–“: {pattern_analysis.get('device_initialization_time', 0):.6f}ç§’
  çœŸã®å®Ÿè¡Œæ™‚é–“: {pattern_analysis.get('true_execution_time', 0):.6f}ç§’
  ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œå¹³å‡: {warmup_data.get('warmup_mean', 0):.6f}ç§’
  ã‚­ãƒ£ãƒƒã‚·ãƒ¥é«˜é€ŸåŒ–: {pattern_analysis.get('cache_speedup', 0):.2f}å€
  åŒæœŸå›æ•°: {data.get('sync_count', 0)}
  ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®‰å®šåŒ–: {pattern_analysis.get('warmup_stabilization', 0):.6f}ç§’
"""
        
        summary += """
### ğŸ” é‡è¦ãªç™ºè¦‹äº‹é …

#### ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã®å½±éŸ¿
- åˆå›ç¬¬1è©¦è¡Œã§ç•°å¸¸ã«é«˜ã„æ™‚é–“ã‚’è¨˜éŒ²ï¼ˆ10-20msç¨‹åº¦ï¼‰
- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œã«ã‚ˆã‚Šå®‰å®šã—ãŸå®Ÿè¡Œæ™‚é–“ã‚’ç¢ºèª
- å¾“æ¥ã®ã€Œã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“æ”¯é…æ€§ã€ã¯ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã®èª¤æ¸¬å®š

#### vmapãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿéš›ã®æ€§èƒ½
- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã®çœŸã®å®Ÿè¡Œæ™‚é–“ã§è©•ä¾¡
- ç†è«–çš„ãƒ™ã‚¯ãƒˆãƒ«åŒ–åŠ¹æœã¨å®Ÿæ¸¬å€¤ã®ä¹–é›¢ã‚’æ¤œè¨¼

#### æ¸¬å®šç²¾åº¦ã®å‘ä¸Š
- çµ±è¨ˆçš„ä¿¡é ¼æ€§: {config.get('measurement_trials', 3)}å›è©¦è¡Œ
- åˆå›ç•°å¸¸å€¤é™¤å¤–ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š
- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã«ã‚ˆã‚‹ãƒ‡ãƒã‚¤ã‚¹å®‰å®šåŒ–

### â„¹ï¸ æ³¨æ„äº‹é …
ã“ã®çµæœã¯æ”¹è‰¯ã•ã‚ŒãŸæ¸¬å®šæ‰‹æ³•ã«ã‚ˆã‚‹å®¢è¦³çš„ãªè¨ˆæ¸¬å€¤ã§ã™ã€‚
- ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å®Ÿè¡Œã«ã‚ˆã‚Šãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã‚’é™¤å»
- åˆå›ç•°å¸¸å€¤é™¤å¤–ã«ã‚ˆã‚‹çµ±è¨ˆç²¾åº¦å‘ä¸Š
- çœŸã®å®Ÿè¡Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã‚’åˆ†é›¢æ¸¬å®š
- å¾“æ¥æ‰‹æ³•ã®å•é¡Œç‚¹ã‚’ä¿®æ­£ã—ãŸä¿¡é ¼æ€§ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿
"""
        
        return summary
    
    def save_results(self, filename: str):
        """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        output_path = f"/tmp/{filename}"
        
        # æ”¹è‰¯ç‰ˆè¨ˆæ¸¬ã‚µãƒãƒªãƒ¼ã‚’è¿½åŠ 
        self.results['measurement_summary'] = self.generate_measurement_summary()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ çµæœä¿å­˜: {output_path}")
        return output_path

def create_arg_parser():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼ä½œæˆ"""
    parser = argparse.ArgumentParser(
        description='æ”¹è‰¯ç‰ˆPyTorch/XLA + AWS Neuronæ€§èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œ
  python performance_pattern_analyzer.py
  
  # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã¨è©¦è¡Œå›æ•°ã‚’å¢—åŠ 
  python performance_pattern_analyzer.py --warmup 10 --trials 15
  
  # åˆå›è©¦è¡Œé™¤å¤–ã‚’ç„¡åŠ¹åŒ–
  python performance_pattern_analyzer.py --no-exclude-first
  
  # ãƒ‡ãƒã‚¤ã‚¹å†åˆæœŸåŒ–ã‚’æœ‰åŠ¹åŒ–ï¼ˆåˆ¶å¾¡å®Ÿé¨“ï¼‰
  python performance_pattern_analyzer.py --enable-reinit
        """
    )
    
    parser.add_argument(
        '--warmup', '-w',
        type=int,
        default=5,
        help='ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—è©¦è¡Œå›æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5)'
    )
    
    parser.add_argument(
        '--trials', '-t',
        type=int,
        default=10,
        help='æ¸¬å®šè©¦è¡Œå›æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10)'
    )
    
    parser.add_argument(
        '--no-exclude-first',
        action='store_true',
        help='åˆå›è©¦è¡Œé™¤å¤–ã‚’ç„¡åŠ¹åŒ–'
    )
    
    parser.add_argument(
        '--enable-reinit',
        action='store_true',
        help='ãƒ‡ãƒã‚¤ã‚¹å†åˆæœŸåŒ–ã‚’æœ‰åŠ¹åŒ–ï¼ˆåˆ¶å¾¡å®Ÿé¨“ç”¨ï¼‰'
    )
    
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='compilation_dominance_analysis.json',
        help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: compilation_dominance_analysis.json)'
    )
    
    return parser

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    print("ğŸš€ æ”¹è‰¯ç‰ˆPyTorch/XLA + AWS Neuronæ€§èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 70)
    print("ç™ºè¦‹ã•ã‚ŒãŸæ¸¬å®šæ‰‹æ³•ã®å•é¡Œã‚’ä¿®æ­£ã—ã€çœŸã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§ã‚’æ¸¬å®šã—ã¾ã™")
    print()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è§£æ
    parser = create_arg_parser()
    args = parser.parse_args()
    
    # è¨­å®šè¡¨ç¤º
    print("ğŸ“‹ æ¸¬å®šè¨­å®š:")
    print(f"  ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—è©¦è¡Œ: {args.warmup}å›")
    print(f"  æ¸¬å®šè©¦è¡Œ: {args.trials}å›")
    print(f"  åˆå›è©¦è¡Œé™¤å¤–: {'ç„¡åŠ¹' if args.no_exclude_first else 'æœ‰åŠ¹'}")
    print(f"  ãƒ‡ãƒã‚¤ã‚¹å†åˆæœŸåŒ–: {'æœ‰åŠ¹' if args.enable_reinit else 'ç„¡åŠ¹'}")
    print(f"  å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {args.output}")
    print()
    
    # XLAãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
    device = ensure_device()
    if device is None:
        print("âŒ XLAãƒ‡ãƒã‚¤ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        print("AWS Neuronç’°å¢ƒã§PyTorch/XLAãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return 1
    
    # æ”¹è‰¯ç‰ˆã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    analyzer = CompilationTimeAnalyzer(
        device=device,
        warmup_iterations=args.warmup,
        measurement_trials=args.trials,
        exclude_first_trial=not args.no_exclude_first,
        enable_device_reinit=args.enable_reinit
    )
    
    try:
        # Phase 1: æ”¹è‰¯ç‰ˆç´”ç²‹åŒæœŸæ™‚é–“æ¸¬å®š
        print("ğŸ”¥ Phase 1: ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã‚’è€ƒæ…®ã—ãŸåŒæœŸæ™‚é–“æ¸¬å®š")
        analyzer.measure_pure_sync_time()
        
        # Phase 2: æ”¹è‰¯ç‰ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³æ¸¬å®š
        print("\nğŸ”¥ Phase 2: ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ä»˜ããƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³æ¸¬å®š")
        analyzer.measure_compilation_patterns()
        
        # Phase 3: æ”¹è‰¯ç‰ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ”¯é…è§£æ
        print("\nğŸ”¥ Phase 3: ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–ã‚’è€ƒæ…®ã—ãŸæ€§èƒ½è§£æ")
        analyzer.analyze_compilation_dominance()
        
        # çµæœä¿å­˜
        result_file = analyzer.save_results(args.output)
        
        # æ”¹è‰¯ç‰ˆè¨ˆæ¸¬çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n" + "="*70)
        print("ğŸ“Š æ”¹è‰¯ç‰ˆæ¸¬å®šçµæœã‚µãƒãƒªãƒ¼")
        print("="*70)
        print(analyzer.generate_measurement_summary())
        print("="*70)
        
        print(f"\nâœ… æ”¹è‰¯ç‰ˆæ€§èƒ½ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æå®Œäº†ï¼")
        print(f"ğŸ“„ è©³ç´°çµæœ: {result_file}")
        print("\nğŸ” ä¸»è¦æ”¹è‰¯ç‚¹:")
        print("  â€¢ ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã«ã‚ˆã‚‹ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–é™¤å»")
        print("  â€¢ çµ±è¨ˆçš„ä¿¡é ¼æ€§å‘ä¸Šï¼ˆè©¦è¡Œå›æ•°å¢—åŠ ï¼‰")
        print("  â€¢ åˆå›ç•°å¸¸å€¤é™¤å¤–ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š")
        print("  â€¢ çœŸã®å®Ÿè¡Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†é›¢æ¸¬å®š")
        print("  â€¢ å¾“æ¥æ‰‹æ³•ã®å•é¡Œç‚¹ä¿®æ­£")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
