#!/usr/bin/env python3
"""
AWS Neuron Hardware Deep Analyzer
==================================

å®Œå…¨ã«ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã§ã®å†…éƒ¨æŒ™å‹•è§£æã«å°‚å¿µã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

ä¸»è¦æ©Ÿèƒ½:
1. Neuron Profiler 2.0ã‚’ä½¿ç”¨ã—ãŸã‚·ã‚¹ãƒ†ãƒ +ãƒ‡ãƒã‚¤ã‚¹ãƒ¬ãƒ™ãƒ«çµ±åˆè§£æ
2. vmap/scan/for-loopã®ç´”ç²‹ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢å†…éƒ¨æŒ™å‹•è§£æ˜
3. NTFF (Neuron Trace File Format) è©³ç´°è§£æ
4. Memory Architecture Deep Dive (HBMâ†”SRAM DMA patterns)
5. Compute Engine Utilization Analysis (Tensor/Vector/Scalar/GPSIMD)
6. Perfettoçµ±åˆã«ã‚ˆã‚‹é«˜åº¦å¯è¦–åŒ–
"""

import os
import sys
import json
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from contextlib import contextmanager
import time

import torch
import torch_xla.core.xla_model as xm
import torch_xla
import numpy as np

# Neuronç’°å¢ƒãƒã‚§ãƒƒã‚¯
try:
    import torch_neuronx
    from torch_neuronx.experimental import profiler
    NEURON_AVAILABLE = True
except ImportError:
    NEURON_AVAILABLE = False
    print("âŒ torch_neuronx not available - Hardware analysis requires Neuron environment")
    sys.exit(1)

# PyTorché–¢æ•°ã®äº’æ›æ€§ãƒã‚§ãƒƒã‚¯  
TORCH_FUNC_AVAILABLE = hasattr(torch, 'func') and hasattr(torch.func, 'scan')

@dataclass
class HardwareProfile:
    """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    pattern_name: str
    
    # Compute Engineåˆ†æ
    tensor_engine_utilization: float
    vector_engine_utilization: float
    scalar_engine_utilization: float
    gpsimd_engine_utilization: float
    engine_overlap_efficiency: float
    
    # Memory Architectureåˆ†æ
    hbm_bandwidth_utilization: float
    sram_usage_efficiency: float
    dma_transfer_count: int
    memory_bound_score: float
    
    # Instruction Levelåˆ†æ
    total_instructions: int
    instruction_categories: Dict[str, int]
    hardware_execution_time_ns: int
    
    # Performance Classification
    is_memory_bound: bool
    is_compute_bound: bool
    bottleneck_type: str
    optimization_recommendations: List[str]

@dataclass
class NTFFAnalysisResult:
    """NTFFè©³ç´°è§£æçµæœ"""
    profile_file_path: str
    neff_file_path: str
    
    # Timelineåˆ†æ
    device_timeline_events: List[Dict]
    system_timeline_events: List[Dict]
    
    # Hardware Metrics
    neuron_core_utilization: Dict[str, float]
    dma_activity_patterns: Dict[str, Any]
    memory_access_patterns: Dict[str, Any]
    
    # Engineåˆ†æ
    compute_engine_breakdown: Dict[str, Dict]
    instruction_dependency_chains: List[Dict]
    
    # Performance Insights
    performance_bottlenecks: List[str]
    hardware_efficiency_score: float

class NeuronHardwareProfiler:
    """Neuron Hardware Deep Profiler"""
    
    # çµ±ä¸€æ¯”è¼ƒæ¡ä»¶è¨­å®šï¼ˆperformance_pattern_analyzer.py ã¨æ•´åˆï¼‰
    UNIFIED_CONDITIONS = {
        'iterations': 3,           # ã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§3å›å‡¦ç†
        'batch_size': 32,         # ãƒãƒƒãƒã‚µã‚¤ã‚º32
        'feature_size': 128,      # ç‰¹å¾´æ¬¡å…ƒ128
        'model_type': 'small'     # smallãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
    }
    
    def __init__(self, analysis_name: str = "hardware_deep_analysis"):
        self.analysis_name = analysis_name
        self.device = torch_xla.device()
        self.profile_output_dir = Path(f"/tmp/neuron_hardware_profiles_{analysis_name}")
        self.profile_output_dir.mkdir(exist_ok=True, parents=True)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¿½è·¡
        self.pattern_profile_mapping = {}
        self.profile_execution_order = []
        
        # ç’°å¢ƒå¤‰æ•°è¨­å®š (Neuron Profiler 2.0)
        os.environ['NEURON_RT_INSPECT_OUTPUT_DIR'] = str(self.profile_output_dir)
        
        self.setup_logging()
        
    def setup_logging(self):
        """è©³ç´°ãƒ­ã‚°è¨­å®šï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        log_file = self.profile_output_dir / "hardware_analysis.log"
        
        # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        logging.getLogger().handlers.clear()
        
        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
        logging.getLogger().setLevel(logging.DEBUG)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆè©³ç´°ãƒ­ã‚°ç”¨ï¼‰
        file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)
        file_formatter = logging.Formatter(
            '%(asctime)s [%(levelname)8s] %(name)s:%(lineno)d - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆé‡è¦ãªæƒ…å ±ã®ã¿ï¼‰
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
        console_handler.setFormatter(console_formatter)
        
        # ãƒ­ã‚¬ãƒ¼è¨­å®š
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.DEBUG)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        # åˆæœŸãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        self.logger.info(f"ğŸ—‚ï¸  Hardware analysis log initialized: {log_file}")
        self.logger.info(f"ğŸ“‚ Profile output directory: {self.profile_output_dir}")
        
        # ç’°å¢ƒæƒ…å ±ãƒ­ã‚°
        self.logger.debug(f"Environment variables:")
        for key, value in os.environ.items():
            if 'NEURON' in key or 'XLA' in key:
                self.logger.debug(f"  {key} = {value}")
        
    def create_test_data(self, shape: Optional[Tuple[int, int]] = None) -> torch.Tensor:
        """çµ±ä¸€æ¡ä»¶ã«åŸºã¥ããƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
        if shape is None:
            # çµ±ä¸€æ¡ä»¶ã‚’ä½¿ç”¨
            shape = (self.UNIFIED_CONDITIONS['batch_size'], self.UNIFIED_CONDITIONS['feature_size'])
        
        self.logger.info(f"Creating test data with unified shape {shape} (batch_size={self.UNIFIED_CONDITIONS['batch_size']}, feature_size={self.UNIFIED_CONDITIONS['feature_size']})")
        tensor = torch.randn(*shape, device=self.device, dtype=torch.float32)
        torch_xla.sync()
        return tensor
        
    @contextmanager
    def hardware_profiling_context(self, pattern_name: str):
        """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ (Neuron Profiler 2.0) - å¼·åŒ–ç‰ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°"""
        self.logger.info(f"ğŸ”¬ Starting hardware profiling for pattern: {pattern_name}")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«é–‹å§‹å‰ã®è©³ç´°çŠ¶æ…‹è¨˜éŒ²
        before_files = set(self.profile_output_dir.glob("**/*.ntff"))
        before_neff_files = set(self.profile_output_dir.glob("**/*.neff"))
        
        self.logger.debug(f"Pre-profiling state for {pattern_name}:")
        self.logger.debug(f"  Output directory: {self.profile_output_dir}")
        self.logger.debug(f"  Existing NTFF files: {len(before_files)}")
        self.logger.debug(f"  Existing NEFF files: {len(before_neff_files)}")
        self.logger.debug(f"  Directory writable: {os.access(self.profile_output_dir, os.W_OK)}")
        
        # é‡è¦ãªç’°å¢ƒå¤‰æ•°ã®ç¢ºèª
        important_env_vars = [
            'NEURON_RT_INSPECT_OUTPUT_DIR', 
            'NEURON_RT_INSPECT_DEVICE_PROFILE',
            'NEURON_RT_ROOT_COMM_ID',
            'NEURON_RT_VISIBLE_CORES'
        ]
        
        for env_var in important_env_vars:
            value = os.environ.get(env_var, 'NOT_SET')
            self.logger.debug(f"  {env_var}: {value}")
        
        profiling_success = False
        profiling_error = None
        
        try:
            # ãƒ‡ãƒã‚¤ã‚¹ãƒ¬ãƒ™ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç’°å¢ƒå¤‰æ•°ã‚’äº‹å‰è¨­å®š
            os.environ['NEURON_RT_INSPECT_DEVICE_PROFILE'] = '1'
            self.logger.debug(f"Set NEURON_RT_INSPECT_DEVICE_PROFILE=1 for {pattern_name}")
            
            # Neuron Profiler 2.0: System + Device profiles
            self.logger.info(f"Initializing profiler with 30-second duration for {pattern_name}")
            
            with profiler.profile(
                port=9012,
                profile_type='system',  # ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
                target='neuron_profile_perfetto',  # Perfettoçµ±åˆ
                output_dir=str(self.profile_output_dir),
                ms_duration=30000  # 30ç§’é–“ã‚­ãƒ£ãƒ—ãƒãƒ£
            ) as prof:
                
                self.logger.debug(f"Profiler context entered successfully for {pattern_name}")
                profiling_success = True
                yield prof
                
        except TimeoutError as e:
            profiling_error = f"Profiling timeout: {e}"
            self.logger.error(f"â±ï¸  Profiling timeout for {pattern_name}: {e}")
            raise
        except ImportError as e:
            profiling_error = f"Profiler import error: {e}"
            self.logger.error(f"ğŸ“¦ Profiler import failed for {pattern_name}: {e}")
            self.logger.error("  â†’ Check if torch_neuronx.experimental.profiler is available")
            raise
        except PermissionError as e:
            profiling_error = f"Permission error: {e}"
            self.logger.error(f"ğŸ”’ Permission error for {pattern_name}: {e}")
            self.logger.error(f"  â†’ Check directory permissions: {self.profile_output_dir}")
            raise
        except Exception as e:
            profiling_error = f"Profiler error: {e}"
            self.logger.error(f"ğŸ’¥ Hardware profiling failed for {pattern_name}: {e}")
            self.logger.error(f"  â†’ Error type: {type(e).__name__}")
            self.logger.error(f"  â†’ Pattern name: {pattern_name}")
            
            # ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ãƒ‡ãƒãƒƒã‚°ãƒ¬ãƒ™ãƒ«ã§ãƒ­ã‚°
            import traceback
            self.logger.debug(f"Full error traceback for {pattern_name}:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    self.logger.debug(f"  {line}")
            raise
        finally:
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å¾Œã®è©³ç´°çŠ¶æ…‹ç¢ºèª
            after_files = set(self.profile_output_dir.glob("**/*.ntff"))
            after_neff_files = set(self.profile_output_dir.glob("**/*.neff"))
            new_files = after_files - before_files
            new_neff_files = after_neff_files - before_neff_files
            
            self.logger.debug(f"Post-profiling state for {pattern_name}:")
            self.logger.debug(f"  Profiling success: {profiling_success}")
            self.logger.debug(f"  New NTFF files: {len(new_files)}")
            self.logger.debug(f"  New NEFF files: {len(new_neff_files)}")
            
            if new_files:
                self.logger.info(f"âœ… Generated {len(new_files)} NTFF files for {pattern_name}")
                for ntff_file in new_files:
                    file_size = ntff_file.stat().st_size
                    self.logger.debug(f"  ğŸ“„ {ntff_file.name} ({file_size:,} bytes)")
            else:
                self.logger.warning(f"âš ï¸  No NTFF files generated for {pattern_name}")
                self.logger.warning(f"  â†’ Profiling success: {profiling_success}")
                if profiling_error:
                    self.logger.warning(f"  â†’ Error: {profiling_error}")
                
                # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è©³ç´°ãƒã‚§ãƒƒã‚¯
                all_files = list(self.profile_output_dir.glob("**/*"))
                self.logger.debug(f"  All files in output dir: {len(all_files)}")
                for f in all_files:
                    if f.is_file():
                        self.logger.debug(f"    {f.name} ({f.stat().st_size} bytes)")
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åã¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ä¿å­˜ï¼ˆæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
            if new_files:
                for ntff_file in new_files:
                    self.pattern_profile_mapping[str(ntff_file)] = pattern_name
                    self.profile_execution_order.append((pattern_name, str(ntff_file)))
                self.logger.info(f"ğŸ“‹ Pattern mapping updated for {pattern_name}")
            else:
                self.logger.warning(f"âš ï¸  No files to map for {pattern_name}")
            
            # ãƒãƒƒãƒ”ãƒ³ã‚°çŠ¶æ³ã®ãƒ­ã‚°
            self.logger.debug(f"Current pattern mapping: {len(self.pattern_profile_mapping)} entries")
            self.logger.debug(f"Current execution order: {len(self.profile_execution_order)} entries")
    
    def analyze_vmap_hardware_behavior(self, data: torch.Tensor) -> HardwareProfile:
        """vmapå†…éƒ¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æï¼ˆçµ±ä¸€æ¡ä»¶ï¼‰"""
        self.logger.info(f"ğŸ§¬ Analyzing vmap hardware behavior with unified conditions (iterations={self.UNIFIED_CONDITIONS['iterations']})")
        
        with self.hardware_profiling_context("vmap_hardware_deep"):
            def vector_operation(x):
                # è¤‡æ•°ã®æ¼”ç®—ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ©ç”¨ã‚’è¦³å¯Ÿ
                result = torch.sum(x * x, dim=-1)  # Tensor Engine
                result = torch.relu(result)        # Vector Engine  
                result = result + 0.1              # Scalar Engine
                return result
                
            # çµ±ä¸€æ¡ä»¶ï¼š3å›ã®ãƒãƒƒãƒå‡¦ç†
            batch_input = data.unsqueeze(0).repeat(self.UNIFIED_CONDITIONS['iterations'], 1, 1)
            vmapped_result = torch.vmap(vector_operation)(batch_input)
            torch_xla.sync()
            
        return self._extract_hardware_profile("vmap_hardware_deep")
    
    def analyze_scan_hardware_behavior(self, data: torch.Tensor) -> HardwareProfile:
        """scanå†…éƒ¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æï¼ˆçµ±ä¸€æ¡ä»¶ï¼‰"""  
        self.logger.info(f"ğŸ”„ Analyzing scan hardware behavior with unified conditions (iterations={self.UNIFIED_CONDITIONS['iterations']})")
        
        with self.hardware_profiling_context("scan_hardware_deep"):
            if TORCH_FUNC_AVAILABLE:
                def scan_function(carry, x):
                    # Sequential computationã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³è¦³å¯Ÿ
                    new_carry = carry + torch.sum(x)  # Memory access pattern
                    intermediate = torch.matmul(x, x.T)  # Tensor Engine utilization
                    return new_carry, new_carry + torch.sum(intermediate)
                
                init_carry = torch.tensor(0.0, device=self.device)
                # çµ±ä¸€æ¡ä»¶ï¼š3å›ã®é †æ¬¡å‡¦ç†
                scan_inputs = data.unsqueeze(0).repeat(self.UNIFIED_CONDITIONS['iterations'], 1, 1)
                final_carry, outputs = torch.func.scan(scan_function, init_carry, scan_inputs)
            else:
                # Fallback implementation with unified conditions
                carry = torch.tensor(0.0, device=self.device)
                for i in range(self.UNIFIED_CONDITIONS['iterations']):
                    carry = carry + torch.sum(data[i % data.size(0)])
            
            torch_xla.sync()
            
        return self._extract_hardware_profile("scan_hardware_deep")
    
    def analyze_for_loop_hardware_behavior(self, data: torch.Tensor, loop_size: str = "medium") -> HardwareProfile:
        """for-loopå†…éƒ¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥å·®åˆ¥åŒ–ç‰ˆï¼‰"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®è¨­å®š
        if loop_size == "small":
            iterations = 3
            complexity_factor = 1
            operation_type = "simple"
        elif loop_size == "medium":
            iterations = 10
            complexity_factor = 2
            operation_type = "moderate"
        else:  # large
            iterations = 30
            complexity_factor = 4
            operation_type = "complex"
        
        self.logger.info(f"ğŸ” Analyzing for-loop hardware behavior - {loop_size} pattern (iterations={iterations}, complexity={complexity_factor})")
        
        try:
            with self.hardware_profiling_context(f"for_loop_hardware_{loop_size}"):
                # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã«å·®åˆ¥åŒ–ã•ã‚ŒãŸå‡¦ç†
                if operation_type == "simple":
                    # Small: åŸºæœ¬çš„ãªç´¯ç©å‡¦ç†
                    result = torch.zeros(data.size(1), device=self.device)
                    for i in range(iterations):
                        idx = i % data.size(0)
                        processed = torch.mean(data[idx])
                        result = result + processed
                        
                elif operation_type == "moderate":
                    # Medium: ã‚ˆã‚Šè¤‡é›‘ãªæ¼”ç®—ãƒ‘ã‚¿ãƒ¼ãƒ³
                    result = torch.zeros(data.size(1), device=self.device)
                    intermediate = torch.zeros(data.size(1), device=self.device)
                    
                    for i in range(iterations):
                        idx = i % data.size(0)
                        # ã‚ˆã‚Šè¤‡é›‘ãªæ¼”ç®—ï¼šelement-wise + matrix operations
                        processed = torch.mean(data[idx] * data[idx])  # Tensor Engineåˆ©ç”¨
                        intermediate = torch.relu(intermediate + processed)  # Vector Engineåˆ©ç”¨
                        result = result + intermediate * 0.1  # Scalar Engineåˆ©ç”¨
                        
                else:  # complex
                    # Large: æœ€ã‚‚è¤‡é›‘ãªæ¼”ç®—ãƒ‘ã‚¿ãƒ¼ãƒ³
                    result = torch.zeros(data.size(1), device=self.device)
                    accumulator = torch.zeros(data.size(1), device=self.device)
                    temp_buffer = torch.zeros(data.size(1), device=self.device)
                    
                    for i in range(iterations):
                        idx = i % data.size(0)
                        # è¤‡é›‘ãªæ¼”ç®—ãƒã‚§ãƒ¼ãƒ³
                        base = data[idx]
                        squared = base * base  # Element-wise multiplication
                        reduced = torch.sum(squared, dim=0, keepdim=True).expand_as(result)  # Reduction + broadcast
                        activated = torch.tanh(reduced)  # Activation function
                        normalized = activated / (torch.norm(activated) + 1e-8)  # Normalization
                        
                        # è¤‡æ•°ã®ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
                        temp_buffer = temp_buffer * 0.9 + normalized * 0.1  # Running average
                        accumulator = accumulator + temp_buffer  # Accumulation
                        result = result + accumulator * (0.01 * (i + 1))  # Weighted accumulation
                
                torch_xla.sync()
                
        except Exception as e:
            self.logger.warning(f"Complex {loop_size} for-loop failed ({e}), trying simplified version")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå°‘ã—å˜ç´”åŒ–ã—ãŸç‰ˆ
            with self.hardware_profiling_context(f"for_loop_hardware_{loop_size}_simple"):
                result = torch.zeros(data.size(1), device=self.device)
                
                # æœ€å°é™ã®å·®åˆ¥åŒ–ã¯ç¶­æŒ
                for i in range(max(3, iterations // 2)):  # æœ€ä½3å›ã€å¤±æ•—æ™‚ã¯åŠåˆ†ã«
                    idx = i % data.size(0)
                    if loop_size == "large":
                        processed = torch.sum(data[idx] * data[idx])  # ã‚ˆã‚Šè¤‡é›‘
                    elif loop_size == "medium":
                        processed = torch.mean(data[idx] * data[idx])  # ä¸­ç¨‹åº¦
                    else:
                        processed = torch.sum(data[idx])  # ã‚·ãƒ³ãƒ—ãƒ«
                    result = result + processed
                    
                torch_xla.sync()
            
        return self._extract_hardware_profile(f"for_loop_hardware_{loop_size}")
    
    def _find_ntff_file_for_pattern(self, pattern_name: str) -> Optional[Path]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åã«å¯¾å¿œã™ã‚‹NTFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        self.logger.info(f"ğŸ” Finding NTFF file for pattern: {pattern_name}")
        
        # 1. execution orderã‹ã‚‰æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        for saved_pattern, ntff_file_path in reversed(self.profile_execution_order):
            if saved_pattern == pattern_name:
                ntff_file = Path(ntff_file_path)
                if ntff_file.exists():
                    self.logger.info(f"âœ… Found NTFF file for {pattern_name}: {ntff_file.name}")
                    return ntff_file
                else:
                    self.logger.warning(f"âš ï¸ NTFF file not found: {ntff_file_path}")
        
        # 2. pattern mappingã‹ã‚‰æ¤œç´¢ (é€†å¼•ã)
        for ntff_file_path, saved_pattern in self.pattern_profile_mapping.items():
            if saved_pattern == pattern_name:
                ntff_file = Path(ntff_file_path)
                if ntff_file.exists():
                    self.logger.info(f"âœ… Found NTFF file via mapping for {pattern_name}: {ntff_file.name}")
                    return ntff_file
        
        # 3. ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚° (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
        all_ntff_files = list(self.profile_output_dir.glob("**/*.ntff"))
        for ntff_file in all_ntff_files:
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åãŒãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if pattern_name in str(ntff_file.name).lower():
                self.logger.info(f"âœ… Found NTFF file via name matching for {pattern_name}: {ntff_file.name}")
                return ntff_file
        
        # 4. ã™ã¹ã¦å¤±æ•—ã—ãŸå ´åˆ
        self.logger.error(f"âŒ No NTFF file found for pattern: {pattern_name}")
        self.logger.info(f"Available files: {[f.name for f in all_ntff_files]}")
        self.logger.info(f"Pattern mapping: {self.pattern_profile_mapping}")
        self.logger.info(f"Execution order: {self.profile_execution_order}")
        
        return None
    
    def _extract_hardware_profile(self, pattern_name: str) -> HardwareProfile:
        """NTFFè§£æã‹ã‚‰ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æŠ½å‡º"""
        self.logger.info(f"ğŸ“Š Extracting hardware profile for {pattern_name}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åã«å¯¾å¿œã™ã‚‹æ­£ã—ã„NTFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
        target_ntff_file = self._find_ntff_file_for_pattern(pattern_name)
        
        if target_ntff_file is None:
            self.logger.warning(f"No specific NTFF file found for {pattern_name}")
            return self._create_fallback_profile(pattern_name)
            
        # NEFF filesæ¤œç´¢
        neff_files = list(self.profile_output_dir.glob("**/*.neff"))
        
        # neuron-profile ã‚³ãƒãƒ³ãƒ‰ã§JSONè§£æ
        ntff_analysis = self._analyze_ntff_with_neuron_profile(target_ntff_file, neff_files[0] if neff_files else None)
        
        # ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º
        return HardwareProfile(
            pattern_name=pattern_name,
            
            # Compute Engineåˆ†æ (NTFFè©³ç´°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰)
            tensor_engine_utilization=ntff_analysis.get('tensor_engine_util', 0.0),
            vector_engine_utilization=ntff_analysis.get('vector_engine_util', 0.0), 
            scalar_engine_utilization=ntff_analysis.get('scalar_engine_util', 0.0),
            gpsimd_engine_utilization=ntff_analysis.get('gpsimd_engine_util', 0.0),
            engine_overlap_efficiency=ntff_analysis.get('engine_overlap_ratio', 0.0),
            
            # Memory Architectureåˆ†æ
            hbm_bandwidth_utilization=ntff_analysis.get('hbm_bandwidth_util', 0.0),
            sram_usage_efficiency=ntff_analysis.get('sram_usage_efficiency', 0.0),
            dma_transfer_count=ntff_analysis.get('dma_transfer_count', 0),
            memory_bound_score=ntff_analysis.get('memory_bound_score', 0.0),
            
            # Instruction Levelåˆ†æ
            total_instructions=ntff_analysis.get('total_instructions', 0),
            instruction_categories=ntff_analysis.get('instruction_categories', {}),
            hardware_execution_time_ns=ntff_analysis.get('hardware_execution_time_ns', 0),
            
            # Performance Classification
            is_memory_bound=ntff_analysis.get('memory_bound_score', 0.0) > 0.6,
            is_compute_bound=ntff_analysis.get('compute_bound_score', 0.0) > 0.6,
            bottleneck_type=ntff_analysis.get('bottleneck_type', 'unknown'),
            optimization_recommendations=ntff_analysis.get('optimization_recommendations', [])
        )
    
    def _analyze_ntff_with_neuron_profile(self, ntff_path: Path, neff_path: Optional[Path]) -> Dict:
        """neuron-profileãƒ„ãƒ¼ãƒ«ã§NTFFè©³ç´°è§£æ"""
        try:
            cmd_args = ['neuron-profile', 'view', '--output-format', 'json', '--output-file', '/tmp/profile_analysis.json']
            
            if neff_path and neff_path.exists():
                cmd_args.extend(['-n', str(neff_path)])
            cmd_args.extend(['-s', str(ntff_path)])
            
            self.logger.info(f"Running: {' '.join(cmd_args)}")
            result = subprocess.run(cmd_args, capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                with open('/tmp/profile_analysis.json', 'r') as f:
                    profile_data = json.load(f)
                return self._process_profile_json(profile_data)
            else:
                self.logger.warning(f"neuron-profile failed: {result.stderr}")
                
        except Exception as e:
            self.logger.error(f"NTFF analysis failed: {e}")
            
        return {}
    
    def _process_profile_json(self, profile_data: Dict) -> Dict:
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«JSONãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
        processed = {}
        
        # Summaryæƒ…å ±æŠ½å‡º
        if 'summary' in profile_data and profile_data['summary']:
            summary = profile_data['summary'][0] if isinstance(profile_data['summary'], list) else profile_data['summary']
            
            processed['hardware_execution_time_ns'] = int(summary.get('total_time', 0) * 1_000_000_000)
            processed['total_instructions'] = summary.get('event_count', 0)
            
            # Engine utilization (æ¦‚ç®—)
            processed['tensor_engine_util'] = summary.get('tensor_utilization', 0.0)
            processed['vector_engine_util'] = summary.get('vector_utilization', 0.0)
            processed['scalar_engine_util'] = summary.get('scalar_utilization', 0.0)
            processed['gpsimd_engine_util'] = summary.get('gpsimd_utilization', 0.0)
        
        # Instructionåˆ†æ
        if 'instruction' in profile_data:
            instructions = profile_data['instruction']
            instruction_categories = {}
            
            for instr in instructions:
                opcode = instr.get('opcode', 'unknown')
                instruction_categories[opcode] = instruction_categories.get(opcode, 0) + 1
            
            processed['instruction_categories'] = instruction_categories
            
            # Memory vs Compute boundåˆ¤å®š
            memory_ops = sum(count for op, count in instruction_categories.items() 
                           if any(mem_op in op.lower() for mem_op in ['load', 'store', 'dma', 'copy']))
            compute_ops = sum(count for op, count in instruction_categories.items()
                            if any(comp_op in op.lower() for comp_op in ['matmul', 'add', 'mul', 'conv']))
            
            total_ops = memory_ops + compute_ops
            if total_ops > 0:
                processed['memory_bound_score'] = memory_ops / total_ops
                processed['compute_bound_score'] = compute_ops / total_ops
            
        # æœ€é©åŒ–æ¨å¥¨ç”Ÿæˆ
        processed['optimization_recommendations'] = self._generate_optimization_recommendations(processed)
        
        return processed
    
    def _generate_optimization_recommendations(self, analysis: Dict) -> List[str]:
        """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æã«åŸºã¥ãæœ€é©åŒ–æ¨å¥¨"""
        recommendations = []
        
        memory_bound_score = analysis.get('memory_bound_score', 0)
        if memory_bound_score > 0.7:
            recommendations.append("Memory-bound: HBMâ†”SRAM transfer optimization required")
            recommendations.append("Consider data layout optimization for better cache locality")
            
        compute_bound_score = analysis.get('compute_bound_score', 0)  
        if compute_bound_score > 0.7:
            recommendations.append("Compute-bound: Engine parallelization optimization required")
            recommendations.append("Consider operation fusion for better hardware utilization")
            
        tensor_util = analysis.get('tensor_engine_util', 0)
        if tensor_util < 0.5:
            recommendations.append("Low Tensor Engine utilization: Consider matrix operation optimization")
            
        return recommendations
    
    def _create_fallback_profile(self, pattern_name: str) -> HardwareProfile:
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.logger.warning(f"Creating fallback profile for {pattern_name}")
        
        return HardwareProfile(
            pattern_name=pattern_name,
            tensor_engine_utilization=0.0,
            vector_engine_utilization=0.0,
            scalar_engine_utilization=0.0,
            gpsimd_engine_utilization=0.0,
            engine_overlap_efficiency=0.0,
            hbm_bandwidth_utilization=0.0,
            sram_usage_efficiency=0.0,
            dma_transfer_count=0,
            memory_bound_score=0.0,
            total_instructions=0,
            instruction_categories={},
            hardware_execution_time_ns=0,
            is_memory_bound=False,
            is_compute_bound=False,
            bottleneck_type="no_data",
            optimization_recommendations=["Profile data unavailable - ensure Neuron Profiler is properly configured"]
        )
    
    def run_comprehensive_hardware_analysis(self) -> Dict[str, HardwareProfile]:
        """åŒ…æ‹¬çš„ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æå®Ÿè¡Œï¼ˆçµ±ä¸€æ¡ä»¶ï¼‰"""
        self.logger.info("ğŸš€ Starting comprehensive hardware analysis with unified conditions")
        
        # çµ±ä¸€æ¡ä»¶ã«åŸºã¥ããƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        test_data = self.create_test_data()  # çµ±ä¸€æ¡ä»¶ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        
        results = {}
        
        # vmap ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æ
        try:
            self.logger.info("Analyzing vmap hardware behavior...")
            results['vmap_hardware'] = self.analyze_vmap_hardware_behavior(test_data)
        except Exception as e:
            self.logger.error(f"vmap analysis failed: {e}")
            
        # scan ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æ  
        try:
            self.logger.info("Analyzing scan hardware behavior...")
            results['scan_hardware'] = self.analyze_scan_hardware_behavior(test_data)
        except Exception as e:
            self.logger.error(f"scan analysis failed: {e}")
            
        # for-loop ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æ (è¤‡æ•°ã‚µã‚¤ã‚º)
        for loop_size in ['small', 'medium', 'large']:
            try:
                self.logger.info(f"Analyzing for-loop hardware behavior ({loop_size})...")
                results[f'for_loop_{loop_size}_hardware'] = self.analyze_for_loop_hardware_behavior(test_data, loop_size)
            except Exception as e:
                self.logger.error(f"for-loop {loop_size} analysis failed: {e}")
                
        self.logger.info("âœ… Comprehensive hardware analysis completed")
        return results
    
    def generate_hardware_analysis_report(self, results: Dict[str, HardwareProfile]) -> str:
        """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report_file = self.profile_output_dir / "hardware_analysis_report.json"
        
        # JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›
        serializable_results = {}
        for pattern_name, profile in results.items():
            serializable_results[pattern_name] = asdict(profile)
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(report_file, 'w') as f:
            json.dump({
                'analysis_timestamp': time.strftime('%Y-%m-%d %H:%M:%S UTC', time.gmtime()),
                'analysis_name': self.analysis_name,
                'neuron_environment': {
                    'neuron_available': NEURON_AVAILABLE,
                    'torch_func_available': TORCH_FUNC_AVAILABLE,
                    'device': str(self.device)
                },
                'hardware_profiles': serializable_results
            }, f, indent=2)
        
        self.logger.info(f"ğŸ“Š Hardware analysis report saved: {report_file}")
        
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ç”¨ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        self._print_hardware_analysis_summary(results)
        
        return str(report_file)
    
    def _print_hardware_analysis_summary(self, results: Dict[str, HardwareProfile]):
        """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "="*100)
        print("ğŸ”¬ NEURON HARDWARE DEEP ANALYSIS SUMMARY")
        print("="*100)
        
        for pattern_name, profile in results.items():
            print(f"\nğŸ“‹ {pattern_name.upper()}")
            print("-" * 60)
            
            # Engine Utilization
            print("ğŸ› ï¸  Compute Engine Utilization:")
            print(f"   Tensor Engine:  {profile.tensor_engine_utilization:.2%}")
            print(f"   Vector Engine:  {profile.vector_engine_utilization:.2%}")
            print(f"   Scalar Engine:  {profile.scalar_engine_utilization:.2%}")
            print(f"   GPSIMD Engine:  {profile.gpsimd_engine_utilization:.2%}")
            print(f"   Engine Overlap: {profile.engine_overlap_efficiency:.2%}")
            
            # Memory Architecture
            print("\nğŸ’¾ Memory Architecture:")
            print(f"   HBM Bandwidth:  {profile.hbm_bandwidth_utilization:.2%}")
            print(f"   SRAM Efficiency: {profile.sram_usage_efficiency:.2%}")
            print(f"   DMA Transfers:   {profile.dma_transfer_count}")
            
            # Performance Classification
            print(f"\nâš¡ Performance Classification:")
            print(f"   Memory Bound:    {'âœ…' if profile.is_memory_bound else 'âŒ'}")
            print(f"   Compute Bound:   {'âœ…' if profile.is_compute_bound else 'âŒ'}")
            print(f"   Bottleneck:      {profile.bottleneck_type}")
            
            # Hardware Execution
            print(f"\nğŸƒ Hardware Execution:")
            print(f"   Total Instructions: {profile.total_instructions:,}")
            print(f"   Execution Time:     {profile.hardware_execution_time_ns:,} ns")
            
            # Optimization Recommendations
            if profile.optimization_recommendations:
                print(f"\nğŸ’¡ Optimization Recommendations:")
                for rec in profile.optimization_recommendations:
                    print(f"   â€¢ {rec}")
            
        print("\n" + "="*100)
    
    def generate_perfetto_analysis(self) -> List[str]:
        """Perfettoçµ±åˆè§£æå®Ÿè¡Œï¼ˆæ„å‘³ã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åä»˜ãï¼‰"""
        self.logger.info("ğŸ¨ Generating Perfetto analysis files with meaningful names...")
        
        perfetto_files = []
        neff_files = list(self.profile_output_dir.glob("**/*.neff"))
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åé †åºã«å¾“ã£ã¦Perfettoãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        pattern_counter = {}
        
        for pattern_name, ntff_file_path in self.profile_execution_order:
            ntff_file = Path(ntff_file_path)
            
            if not ntff_file.exists():
                self.logger.warning(f"NTFF file not found: {ntff_file}")
                continue
                
            try:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³åãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
                if pattern_name in pattern_counter:
                    pattern_counter[pattern_name] += 1
                    suffix = f"_{pattern_counter[pattern_name]}"
                else:
                    pattern_counter[pattern_name] = 1
                    suffix = ""
                
                # æ„å‘³ã®ã‚ã‚‹Perfettoãƒ•ã‚¡ã‚¤ãƒ«å
                perfetto_filename = f"{pattern_name}_hardware{suffix}.pftrace"
                perfetto_output = self.profile_output_dir / perfetto_filename
                
                neff_file = neff_files[0] if neff_files else None
                
                cmd_args = [
                    'neuron-profile', 'view',
                    '--output-format', 'perfetto',
                    '--output-file', str(perfetto_output)
                ]
                
                if neff_file:
                    cmd_args.extend(['-n', str(neff_file)])
                cmd_args.extend(['-s', str(ntff_file)])
                
                result = subprocess.run(cmd_args, capture_output=True, text=True, timeout=120)
                
                if result.returncode == 0:
                    perfetto_files.append(str(perfetto_output))
                    self.logger.info(f"âœ… Perfetto file generated: {perfetto_filename} (from {pattern_name})")
                else:
                    self.logger.warning(f"Perfetto generation failed for {pattern_name}: {result.stderr}")
                    
            except Exception as e:
                self.logger.error(f"Perfetto analysis failed for {pattern_name} ({ntff_file}): {e}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not perfetto_files:
            self.logger.warning("No pattern mapping found, using fallback numbering...")
            profile_files = list(self.profile_output_dir.glob("**/*.ntff"))
            
            for i, ntff_file in enumerate(profile_files):
                try:
                    perfetto_output = self.profile_output_dir / f"unknown_pattern_{i}.pftrace"
                    
                    cmd_args = [
                        'neuron-profile', 'view',
                        '--output-format', 'perfetto',
                        '--output-file', str(perfetto_output)
                    ]
                    
                    if neff_files:
                        cmd_args.extend(['-n', str(neff_files[0])])
                    cmd_args.extend(['-s', str(ntff_file)])
                    
                    result = subprocess.run(cmd_args, capture_output=True, text=True, timeout=120)
                    
                    if result.returncode == 0:
                        perfetto_files.append(str(perfetto_output))
                        self.logger.info(f"Fallback Perfetto file generated: {perfetto_output}")
                        
                except Exception as e:
                    self.logger.error(f"Fallback Perfetto generation failed: {e}")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ä¿å­˜
        self._save_perfetto_pattern_mapping(perfetto_files)
        
        return perfetto_files
    
    def _save_perfetto_pattern_mapping(self, perfetto_files: List[str]):
        """Perfettoãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ä¿å­˜"""
        mapping_file = self.profile_output_dir / "perfetto_pattern_mapping.json"
        
        mapping_data = {
            'pattern_execution_order': self.profile_execution_order,
            'pattern_profile_mapping': self.pattern_profile_mapping,
            'perfetto_files': perfetto_files,
            'generated_timestamp': time.strftime('%Y-%m-%d %H:%M:%S UTC', time.gmtime())
        }
        
        with open(mapping_file, 'w') as f:
            json.dump(mapping_data, f, indent=2)
        
        self.logger.info(f"Pattern mapping saved: {mapping_file}")


def main():
    """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ·±å±¤è§£æãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ”¬ AWS Neuron Hardware Deep Analyzer")
    print("=" * 50)
    print("âš ï¸  æ³¨æ„: å¾“æ¥ã®æ™‚é–“æ¸¬å®šã¯å®Œå…¨å»ƒæ­¢ - ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«è§£æã®ã¿å®Ÿè¡Œ")
    print()
    
    if not NEURON_AVAILABLE:
        print("âŒ Neuron environment required for hardware analysis")
        sys.exit(1)
    
    try:
        # ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ·±å±¤è§£æå®Ÿè¡Œ
        analyzer = NeuronHardwareProfiler("comprehensive_hardware_deep_analysis")
        
        # åŒ…æ‹¬çš„ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æ
        hardware_profiles = analyzer.run_comprehensive_hardware_analysis()
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_file = analyzer.generate_hardware_analysis_report(hardware_profiles)
        
        # Perfettoçµ±åˆè§£æ
        perfetto_files = analyzer.generate_perfetto_analysis()
        
        # çµæœã‚µãƒãƒªãƒ¼
        print("\nâœ… Hardware Deep Analysis completed successfully!")
        print(f"ğŸ“Š Detailed report: {report_file}")
        print(f"ğŸ“ Profile directory: {analyzer.profile_output_dir}")
        
        if perfetto_files:
            print("ğŸ¨ Perfetto analysis files:")
            for pf in perfetto_files:
                print(f"   â€¢ {pf}")
            print("   â†’ View at: https://ui.perfetto.dev/")
        
        print("\nğŸ”¬ Hardware analysis focus areas achieved:")
        print("   â€¢ Compute Engine utilization patterns")
        print("   â€¢ Memory architecture deep dive")
        print("   â€¢ Instruction-level timeline analysis")
        print("   â€¢ vmap/scan/for-loop hardware behavior comparison")
        
    except Exception as e:
        print(f"âŒ Hardware analysis failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
