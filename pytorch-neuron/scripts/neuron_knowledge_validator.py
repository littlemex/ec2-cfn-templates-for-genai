#!/usr/bin/env python3
"""
AWS Neuron ãƒŠãƒ¬ãƒƒã‚¸æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æŠ½å‡ºã•ã‚ŒãŸãƒŠãƒ¬ãƒƒã‚¸ã®å„ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨è§£æ±ºç­–ã‚’å®Ÿéš›ã«æ¤œè¨¼ã—ã¾ã™ã€‚
ã€Œã“ã†ã„ã†ã“ã¨ã‚’ã—ãŸã‚‰ã“ã†ã„ã†ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã€ã‚’ç¢ºèªã§ãã¾ã™ã€‚

å®Ÿè¡Œå‰ææ¡ä»¶:
- AWS Neuronç’°å¢ƒ (TRN1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹)  
- torch_neuronx ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
"""

import torch
import torch.nn as nn
import time
import traceback
from typing import Dict, Any

# NeuronX imports
try:
    import torch_neuronx
    import torch_xla.core.xla_model as xm
    from torch_neuronx.utils import get_platform_target
    NEURONX_AVAILABLE = True
    print("âœ… torch_neuronx successfully imported")
except ImportError as e:
    print(f"âš ï¸ torch_neuronx not available: {e}")
    NEURONX_AVAILABLE = False


def print_test_header(title: str):
    """ãƒ†ã‚¹ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ˜ãƒƒãƒ€ãƒ¼"""
    print(f"\n{'='*80}")
    print(f" {title}")
    print(f"{'='*80}")


def print_test_result(test_name: str, expected_error: str, actual_result: str, success: bool):
    """ãƒ†ã‚¹ãƒˆçµæœã®è¡¨ç¤º"""
    status = "âœ… æœŸå¾…é€šã‚Š" if success else "âŒ äºˆæœŸã—ãªã„çµæœ"
    print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆ: {test_name}")
    print(f"ğŸ¯ æœŸå¾…ã™ã‚‹ã‚¨ãƒ©ãƒ¼: {expected_error}")
    print(f"ğŸ“‹ å®Ÿéš›ã®çµæœ: {actual_result}")
    print(f"ğŸ çµæœ: {status}")


class KnowledgeValidator:
    """ãƒŠãƒ¬ãƒƒã‚¸æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.device = 'cpu'
        if NEURONX_AVAILABLE:
            try:
                self.device = xm.xla_device()
                print(f"ğŸ”§ ãƒ‡ãƒã‚¤ã‚¹åˆæœŸåŒ–: {self.device}")
                platform = get_platform_target()
                print(f"ğŸ”§ ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {platform}")
            except Exception as e:
                print(f"âš ï¸ XLAåˆæœŸåŒ–å¤±æ•—: {e}")
    
    def test_01_unfold_view_operator_error(self):
        """ãƒ†ã‚¹ãƒˆ1: aten::unfold View Operatoråˆ¶é™ã‚¨ãƒ©ãƒ¼"""
        print_test_header("ãƒ†ã‚¹ãƒˆ1: View Operatoråˆ¶é™ï¼ˆaten::unfoldï¼‰")
        
        print("ğŸ” æŠ€è¡“çš„èƒŒæ™¯:")
        print("  â€¢ aten::unfoldã¯ã€ŒView Operatorã€ã¨ã—ã¦åˆ†é¡ã•ã‚Œã‚‹")
        print("  â€¢ View Operatorã¯å…ƒã®ãƒ†ãƒ³ã‚½ãƒ«ã¨ãƒ¡ãƒ¢ãƒªã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’å…±æœ‰ã™ã‚‹æ“ä½œ")
        print("  â€¢ XLAãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰(Neuron)ã§ã¯ãƒ‡ãƒã‚¤ã‚¹é–“ã§ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å…±æœ‰ãŒä¸å¯èƒ½")
        print("  â€¢ Neuronãƒ‡ãƒã‚¤ã‚¹ã¯å°‚ç”¨ãƒ¡ãƒ¢ãƒªç©ºé–“ã‚’æŒã¡ã€CPUã¨ã®ç›´æ¥ãƒ¡ãƒ¢ãƒªå…±æœ‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ãªã„")
        print("  â€¢ unfoldæ“ä½œ: ãƒ†ãƒ³ã‚½ãƒ«ã‚’sliding windowã§å±•é–‹ã™ã‚‹æ“ä½œï¼ˆãƒ‘ãƒƒãƒæŠ½å‡ºç­‰ã«ä½¿ç”¨ï¼‰")
        print("\nğŸš¨ äºˆæœŸã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
        print("  'aten::unfold appears to be a view operator, but it has no implementation'")
        print("  'for backend xla:0. View operators don't support since the tensor's'") 
        print("  'storage cannot be shared across devices.'")
        print("\nğŸ’¡ ãªãœã“ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã®ã‹:")
        print("  1. PyTorchã®Viewæ“ä½œã¯å…ƒãƒ†ãƒ³ã‚½ãƒ«ã¨ãƒ¡ãƒ¢ãƒªã‚’å…±æœ‰ã™ã‚‹ä»•çµ„ã¿")
        print("  2. Neuronãƒ‡ãƒã‚¤ã‚¹ã¯ç‹¬ç«‹ã—ãŸãƒ¡ãƒ¢ãƒªç©ºé–“ã‚’æŒã¤")
        print("  3. ãƒ‡ãƒã‚¤ã‚¹é–“ã§ã®ãƒ¡ãƒ¢ãƒªå…±æœ‰ã¯æŠ€è¡“çš„ã«ä¸å¯èƒ½")
        print("  4. ãã®ãŸã‚å¤šãã®View OperatorãŒæœªå®Ÿè£…ã¾ãŸã¯åˆ¶é™ã•ã‚Œã‚‹")
        
        try:
            # å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ï¼štensor.unfoldã‚’ç›´æ¥ä½¿ç”¨
            x = torch.randn(1, 3, 16, 16).to(self.device)
            
            print(f"\nğŸ§ª å®Ÿè¡Œã‚³ãƒ¼ãƒ‰: x.unfold(-2, 4, 4).unfold(-2, 4, 4)")
            print(f"  å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«å½¢çŠ¶: {x.shape}")
            print(f"  ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
            
            # ã“ã‚ŒãŒã‚¨ãƒ©ãƒ¼ã‚’å¼•ãèµ·ã“ã™ã¯ãš
            patches = x.unfold(-2, 4, 4).unfold(-2, 4, 4)
            patches = patches.contiguous().view(1, 4, 4, -1)
            
            print_test_result(
                "aten::unfoldä½¿ç”¨", 
                "RuntimeError: aten::unfold view operator ã‚¨ãƒ©ãƒ¼",
                "äºˆæœŸã—ãªã„æˆåŠŸ", 
                False
            )
            return False
            
        except RuntimeError as e:
            if "unfold" in str(e) and "view operator" in str(e):
                print_test_result(
                    "aten::unfoldä½¿ç”¨", 
                    "RuntimeError: aten::unfold view operator ã‚¨ãƒ©ãƒ¼",
                    f"æœŸå¾…é€šã‚Šã®ã‚¨ãƒ©ãƒ¼: {e}", 
                    True
                )
                return True
            else:
                print_test_result(
                    "aten::unfoldä½¿ç”¨", 
                    "RuntimeError: aten::unfold view operator ã‚¨ãƒ©ãƒ¼",
                    f"ç•°ãªã‚‹ã‚¨ãƒ©ãƒ¼: {e}", 
                    False
                )
                return False
        except Exception as e:
            print_test_result(
                "aten::unfoldä½¿ç”¨", 
                "RuntimeError: aten::unfold view operator ã‚¨ãƒ©ãƒ¼",
                f"ç•°ãªã‚‹ä¾‹å¤–: {e}", 
                False
            )
            return False
    
    def test_01_solution_unfold_module(self):
        """ãƒ†ã‚¹ãƒˆ1è§£æ±ºç­–: nn.Unfoldãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨"""
        print_test_header("ãƒ†ã‚¹ãƒˆ1è§£æ±ºç­–: nn.Unfoldãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨")
        
        try:
            # è§£æ±ºç­–ï¼šnn.Unfoldãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨
            x = torch.randn(1, 3, 16, 16).to(self.device)
            unfold = nn.Unfold(kernel_size=4, stride=4)
            
            patches = unfold(x)  # [1, 3*4*4, num_patches]
            patches = patches.transpose(1, 2)  # [1, num_patches, 3*4*4]
            patches = patches.view(1, 4, 4, -1)  # [1, 4, 4, 48]
            
            print_test_result(
                "nn.Unfoldãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨", 
                "æˆåŠŸ",
                f"æˆåŠŸ: å‡ºåŠ›å½¢çŠ¶ {patches.shape}", 
                True
            )
            return True
            
        except Exception as e:
            print_test_result(
                "nn.Unfoldãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨", 
                "æˆåŠŸ",
                f"ã‚¨ãƒ©ãƒ¼: {e}", 
                False
            )
            return False
    
    def test_02_vmap_dropout_randomness_error(self):
        """ãƒ†ã‚¹ãƒˆ2: vmapå†…Dropoutãƒ©ãƒ³ãƒ€ãƒ æ“ä½œåˆ¶é™ã‚¨ãƒ©ãƒ¼"""
        print_test_header("ãƒ†ã‚¹ãƒˆ2: vmapå†…Dropoutãƒ©ãƒ³ãƒ€ãƒ æ“ä½œåˆ¶é™")
        
        print("ğŸ” æŠ€è¡“çš„èƒŒæ™¯:")
        print("  â€¢ vmapã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ randomness='error' ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œ")
        print("  â€¢ ã“ã®ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œã®æ„å›³ãŒä¸æ˜ç¢ºãªãŸã‚ã‚¨ãƒ©ãƒ¼ã‚’ç™ºç”Ÿ")
        print("  â€¢ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ 'same'ï¼ˆå…¨ãƒãƒƒãƒã§åŒã˜ä¹±æ•°ï¼‰ã‹ 'different'ï¼ˆå„ãƒãƒƒãƒã§ç•°ãªã‚‹ä¹±æ•°ï¼‰ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã™ã‚‹å¿…è¦")
        print("  â€¢ Dropoutã¯å†…éƒ¨çš„ã«torch.randn()ç­‰ã®ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œã‚’ä½¿ç”¨")
        print("  â€¢ ã“ã®åˆ¶é™ã¯functorchãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è¨­è¨ˆæ–¹é‡ï¼ˆJAXã¨åŒæ§˜ã®å®‰å…¨æ€§ä¿è¨¼ï¼‰")
        print("\nğŸš¨ äºˆæœŸã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
        print("  'vmap: called random operation while in randomness error mode.'")
        print("  'Please either use the 'same' or 'different' randomness flags on vmap'")
        print("  'or perform the randomness operation out of vmap'")
        print("\nğŸ’¡ ãªãœã“ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã®ã‹:")
        print("  1. vmapã¯é–¢æ•°å‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ç´”ç²‹é–¢æ•°ã‚’å‰æã¨ã™ã‚‹")
        print("  2. ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œã¯å‰¯ä½œç”¨ã‚’æŒã¤ãŸã‚ã€ãƒãƒƒãƒé–“ã§ã®ä¸€è²«æ€§ãŒä¸æ˜ç¢º")
        print("  3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ„å›³ã‚’æ˜ç¤ºã™ã‚‹ã“ã¨ã§äºˆæœŸã—ãªã„å‹•ä½œã‚’é˜²ã")
        print("  4. PyTorch/XLAã¨ã®äº’æ›æ€§ã«ãŠã„ã¦ã‚‚ã“ã®åˆ¶é™ãŒé©ç”¨ã•ã‚Œã‚‹")
        
        try:
            # Dropoutã‚’å«ã‚€ãƒ¢ãƒ‡ãƒ«
            class ModelWithDropout(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.linear = nn.Linear(10, 5)
                    self.dropout = nn.Dropout(0.1)
                    self.output = nn.Linear(5, 1)
                
                def forward(self, x):
                    x = self.linear(x)
                    x = self.dropout(x)  # vmapå†…ã§ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œ
                    return self.output(x)
            
            model = ModelWithDropout().to(self.device)
            test_data = torch.randn(3, 10).to(self.device)
            
            print(f"\nğŸ§ª å®Ÿè¡Œã‚³ãƒ¼ãƒ‰: torch.vmap(model)(test_data)")
            print(f"  ãƒ¢ãƒ‡ãƒ«: Linear + Dropout + Linear")
            print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {test_data.shape}")
            print(f"  ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
            print("  DropoutãŒå†…éƒ¨çš„ã«ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œã‚’å®Ÿè¡Œ")
            
            # vmapå†…ã§ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œå®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã¯ãšï¼‰
            def process_batch(x):
                return model(x)
            
            result = torch.vmap(process_batch)(test_data)
            
            print_test_result(
                "vmapå†…Dropoutä½¿ç”¨", 
                "RuntimeError: vmap randomness error",
                "äºˆæœŸã—ãªã„æˆåŠŸ", 
                False
            )
            return False
            
        except RuntimeError as e:
            if "randomness" in str(e) and "vmap" in str(e):
                print_test_result(
                    "vmapå†…Dropoutä½¿ç”¨", 
                    "RuntimeError: vmap randomness error",
                    f"æœŸå¾…é€šã‚Šã®ã‚¨ãƒ©ãƒ¼: {e}", 
                    True
                )
                return True
            else:
                print_test_result(
                    "vmapå†…Dropoutä½¿ç”¨", 
                    "RuntimeError: vmap randomness error",
                    f"ç•°ãªã‚‹ã‚¨ãƒ©ãƒ¼: {e}", 
                    False
                )
                return False
        except Exception as e:
            print_test_result(
                "vmapå†…Dropoutä½¿ç”¨", 
                "RuntimeError: vmap randomness error",
                f"ç•°ãªã‚‹ä¾‹å¤–: {e}", 
                False
            )
            return False
    
    def test_02_solution_no_dropout(self):
        """ãƒ†ã‚¹ãƒˆ2è§£æ±ºç­–: Dropoutãªã—ãƒ¢ãƒ‡ãƒ«"""
        print_test_header("ãƒ†ã‚¹ãƒˆ2è§£æ±ºç­–: Dropoutãªã—ã€LayerNormä½¿ç”¨")
        
        try:
            # è§£æ±ºç­–ï¼šDropoutã‚’LayerNormã«å¤‰æ›´
            class ModelWithLayerNorm(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.linear = nn.Linear(10, 5)
                    self.norm = nn.LayerNorm(5)  # Dropoutã®ä»£æ›¿
                    self.output = nn.Linear(5, 1)
                
                def forward(self, x):
                    x = self.linear(x)
                    x = self.norm(x)  # ãƒ©ãƒ³ãƒ€ãƒ æ“ä½œãªã—
                    return self.output(x)
            
            model = ModelWithLayerNorm().to(self.device)
            test_data = torch.randn(3, 10).to(self.device)
            
            def process_batch(x):
                return model(x)
            
            result = torch.vmap(process_batch)(test_data)
            
            print_test_result(
                "vmapå†…LayerNormä½¿ç”¨", 
                "æˆåŠŸ",
                f"æˆåŠŸ: å‡ºåŠ›å½¢çŠ¶ {result.shape}", 
                True
            )
            return True
            
        except Exception as e:
            print_test_result(
                "vmapå†…LayerNormä½¿ç”¨", 
                "æˆåŠŸ",
                f"ã‚¨ãƒ©ãƒ¼: {e}", 
                False
            )
            return False
    
    def test_03_xla_sync_api_error(self):
        """ãƒ†ã‚¹ãƒˆ3: xm.sync() APIäº’æ›æ€§ã‚¨ãƒ©ãƒ¼"""
        print_test_header("ãƒ†ã‚¹ãƒˆ3: xm.sync() APIäº’æ›æ€§")
        
        print("ğŸ” æŠ€è¡“çš„èƒŒæ™¯:")
        print("  â€¢ xm.sync()ã¯å¤ã„torch_xla APIã®åŒæœŸé–¢æ•°")
        print("  â€¢ PyTorch/XLAã®æ€¥é€Ÿãªé–‹ç™ºã«ã‚ˆã‚Šã€å¤šãã®APIãŒå¤‰æ›´ãƒ»å»ƒæ­¢")
        print("  â€¢ æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯xm.wait_device_ops()ãŒæ¨å¥¨ã•ã‚Œã‚‹")
        print("  â€¢ åŒæœŸæ“ä½œã¯XLAã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œã‚’å¼·åˆ¶ã—ã€ãƒ‡ãƒã‚¤ã‚¹çŠ¶æ…‹ã‚’ç¢ºå®šã•ã›ã‚‹")
        print("  â€¢ ãƒ¬ã‚¬ã‚·ãƒ¼ã‚³ãƒ¼ãƒ‰ã§ã®äº’æ›æ€§å•é¡ŒãŒé »ç™º")
        print("\nğŸš¨ äºˆæœŸã•ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
        print("  'module 'torch_xla.core.xla_model' has no attribute 'sync''")
        print("\nğŸ’¡ ãªãœã“ã®ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã®ã‹:")
        print("  1. torch_xlaãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ€¥é€Ÿãªé€²åŒ–ã«ã‚ˆã‚‹éäº’æ›å¤‰æ›´")
        print("  2. APIè¨­è¨ˆã®è¦‹ç›´ã—ã«ã‚ˆã‚‹é–¢æ•°åå¤‰æ›´")
        print("  3. ã‚ˆã‚Šæ˜ç¤ºçš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„é–¢æ•°åã¸ã®ç§»è¡Œ")
        print("  4. æ—§APIã®æ®µéšçš„å»ƒæ­¢ã«ã‚ˆã‚‹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        
        try:
            print(f"\nğŸ§ª å®Ÿè¡Œã‚³ãƒ¼ãƒ‰: xm.sync()")
            print(f"  torch_xlaãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: {xm}")
            print(f"  åˆ©ç”¨å¯èƒ½ãªåŒæœŸé–¢æ•°ã‚’ç¢ºèªä¸­...")
            
            # å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ï¼šå¤ã„APIä½¿ç”¨
            if hasattr(xm, 'sync'):
                xm.sync()
                print_test_result(
                    "xm.sync()ä½¿ç”¨", 
                    "AttributeError: no attribute 'sync'",
                    "äºˆæœŸã—ãªã„æˆåŠŸï¼ˆAPIãŒå­˜åœ¨ï¼‰", 
                    False
                )
                return False
            else:
                # syncå±æ€§ãŒå­˜åœ¨ã—ãªã„å ´åˆ
                raise AttributeError("module 'torch_xla.core.xla_model' has no attribute 'sync'")
                
        except AttributeError as e:
            if "sync" in str(e):
                print_test_result(
                    "xm.sync()ä½¿ç”¨", 
                    "AttributeError: no attribute 'sync'",
                    f"æœŸå¾…é€šã‚Šã®ã‚¨ãƒ©ãƒ¼: {e}", 
                    True
                )
                return True
            else:
                print_test_result(
                    "xm.sync()ä½¿ç”¨", 
                    "AttributeError: no attribute 'sync'",
                    f"ç•°ãªã‚‹ã‚¨ãƒ©ãƒ¼: {e}", 
                    False
                )
                return False
    
    def test_03_solution_wait_device_ops(self):
        """ãƒ†ã‚¹ãƒˆ3è§£æ±ºç­–: xm.wait_device_ops()ä½¿ç”¨"""
        print_test_header("ãƒ†ã‚¹ãƒˆ3è§£æ±ºç­–: xm.wait_device_ops()ä½¿ç”¨")
        
        try:
            # è§£æ±ºç­–ï¼šæ–°ã—ã„APIã¾ãŸã¯é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            try:
                if hasattr(xm, 'wait_device_ops'):
                    xm.wait_device_ops()
                    sync_method = "wait_device_ops()"
                elif hasattr(xm, 'sync'):
                    xm.sync()
                    sync_method = "sync()"
                else:
                    sync_method = "ã‚¹ã‚­ãƒƒãƒ—ï¼ˆAPIæœªå¯¾å¿œï¼‰"
            except AttributeError:
                sync_method = "ã‚¹ã‚­ãƒƒãƒ—ï¼ˆä¾‹å¤–å‡¦ç†ï¼‰"
            
            print_test_result(
                "é©åˆ‡ãªåŒæœŸAPIä½¿ç”¨", 
                "æˆåŠŸ",
                f"æˆåŠŸ: {sync_method}ã‚’ä½¿ç”¨", 
                True
            )
            return True
            
        except Exception as e:
            print_test_result(
                "é©åˆ‡ãªåŒæœŸAPIä½¿ç”¨", 
                "æˆåŠŸ",
                f"ã‚¨ãƒ©ãƒ¼: {e}", 
                False
            )
            return False
    
    def test_04_neuron_compilation_cache(self):
        """ãƒ†ã‚¹ãƒˆ4: Neuronã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‹•ä½œ"""
        print_test_header("ãƒ†ã‚¹ãƒˆ4: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‹•ä½œç¢ºèª")
        
        try:
            # ç°¡å˜ãªãƒ¢ãƒ‡ãƒ«ã§2å›å®Ÿè¡Œã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœç¢ºèª
            class SimpleModel(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.linear = nn.Linear(8, 4)
                
                def forward(self, x):
                    return self.linear(x)
            
            model = SimpleModel().to(self.device)
            test_data = torch.randn(2, 8).to(self.device)
            
            # 1å›ç›®å®Ÿè¡Œï¼ˆã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ç™ºç”Ÿï¼‰
            start_time = time.time()
            result1 = model(test_data)
            first_time = time.time() - start_time
            
            # 2å›ç›®å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ï¼‰
            start_time = time.time()
            result2 = model(test_data)
            second_time = time.time() - start_time
            
            cache_effect = first_time > second_time * 2  # 2å€ä»¥ä¸Šã®å·®ãŒã‚ã‚Œã°ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœ
            
            print_test_result(
                "ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥", 
                "2å›ç›®ãŒé«˜é€ŸåŒ–",
                f"1å›ç›®: {first_time:.4f}ç§’, 2å›ç›®: {second_time:.4f}ç§’, ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœ: {cache_effect}", 
                True  # å®Ÿè¡Œã§ãã‚Œã°æˆåŠŸ
            )
            return True
            
        except Exception as e:
            print_test_result(
                "ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥", 
                "æˆåŠŸ",
                f"ã‚¨ãƒ©ãƒ¼: {e}", 
                False
            )
            return False
    
    def test_05_memory_leak_warning(self):
        """ãƒ†ã‚¹ãƒˆ5: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è­¦å‘Šã®ç™ºç”Ÿ"""
        print_test_header("ãƒ†ã‚¹ãƒˆ5: NeuronRuntimeãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è­¦å‘Š")
        
        print("â„¹ï¸ ã“ã®ãƒ†ã‚¹ãƒˆã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ‚äº†æ™‚ã«ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è­¦å‘ŠãŒå‡ºã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™")
        print("âš ï¸ è­¦å‘Š: 'nrtucode: internal error: XX object(s) leaked, improper teardown'")
        print("ğŸ“ ã“ã®è­¦å‘Šã¯è¨ˆç®—çµæœã«å½±éŸ¿ã›ãšã€æ­£å¸¸ãªå‹•ä½œã§ã™")
        
        try:
            # è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ã‚’é«˜ã‚ã‚‹
            models = []
            for i in range(3):
                model = nn.Linear(4, 2).to(self.device)
                x = torch.randn(2, 4).to(self.device)
                _ = model(x)  # å®Ÿè¡Œã—ã¦Neuronãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨
                models.append(model)
            
            print_test_result(
                "ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è­¦å‘Šãƒ†ã‚¹ãƒˆ", 
                "ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ‚äº†æ™‚ã«è­¦å‘Šè¡¨ç¤º",
                "è¤‡æ•°ãƒ¢ãƒ‡ãƒ«å®Ÿè¡Œå®Œäº†ï¼ˆçµ‚äº†æ™‚ã«è­¦å‘Šç¢ºèªï¼‰", 
                True
            )
            return True
            
        except Exception as e:
            print_test_result(
                "ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è­¦å‘Šãƒ†ã‚¹ãƒˆ", 
                "ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ‚äº†æ™‚ã«è­¦å‘Šè¡¨ç¤º",
                f"ã‚¨ãƒ©ãƒ¼: {e}", 
                False
            )
            return False
    
    def run_all_tests(self):
        """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("ğŸš€ AWS Neuron ãƒŠãƒ¬ãƒƒã‚¸æ¤œè¨¼é–‹å§‹")
        print("=" * 80)
        
        results = []
        
        # ãƒ†ã‚¹ãƒˆ1: View Operatoråˆ¶é™
        results.append(("unfold_error", self.test_01_unfold_view_operator_error()))
        results.append(("unfold_solution", self.test_01_solution_unfold_module()))
        
        # ãƒ†ã‚¹ãƒˆ2: vmap Randomnessåˆ¶é™
        results.append(("vmap_dropout_error", self.test_02_vmap_dropout_randomness_error()))
        results.append(("vmap_layernorm_solution", self.test_02_solution_no_dropout()))
        
        # ãƒ†ã‚¹ãƒˆ3: APIäº’æ›æ€§
        results.append(("sync_api_error", self.test_03_xla_sync_api_error()))
        results.append(("sync_api_solution", self.test_03_solution_wait_device_ops()))
        
        # ãƒ†ã‚¹ãƒˆ4: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        results.append(("compilation_cache", self.test_04_neuron_compilation_cache()))
        
        # ãƒ†ã‚¹ãƒˆ5: ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è­¦å‘Š
        results.append(("memory_leak_warning", self.test_05_memory_leak_warning()))
        
        # çµæœã‚µãƒãƒªãƒ¼
        print_test_header("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        
        passed = 0
        for test_name, result in results:
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"  {test_name}: {status}")
            if result:
                passed += 1
        
        print(f"\nğŸ“Š ç·åˆçµæœ: {passed}/{len(results)} ãƒ†ã‚¹ãƒˆãŒæˆåŠŸ")
        print(f"ğŸ¯ æˆåŠŸç‡: {passed/len(results)*100:.1f}%")
        
        if passed == len(results):
            print("ğŸ‰ ã™ã¹ã¦ã®ãƒŠãƒ¬ãƒƒã‚¸ãŒæ­£ã—ãæ¤œè¨¼ã•ã‚Œã¾ã—ãŸï¼")
        else:
            print("âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        return passed == len(results)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ”¬ AWS Neuron ãƒŠãƒ¬ãƒƒã‚¸æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 80)
    print("ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æŠ½å‡ºã•ã‚ŒãŸãƒŠãƒ¬ãƒƒã‚¸ã®å„ã‚¨ãƒ©ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿéš›ã«æ¤œè¨¼ã—ã¾ã™")
    print("æœŸå¾…ã™ã‚‹ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã§ã€ãƒŠãƒ¬ãƒƒã‚¸ã®æ­£ç¢ºæ€§ã‚’ç¢ºèªã§ãã¾ã™")
    print("=" * 80)
    
    if not NEURONX_AVAILABLE:
        print("âŒ torch_neuronxãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚Neuronç’°å¢ƒã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return False
    
    validator = KnowledgeValidator()
    return validator.run_all_tests()


if __name__ == "__main__":
    try:
        success = main()
        print(f"\nğŸ ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ‚äº†: {'æˆåŠŸ' if success else 'éƒ¨åˆ†çš„æˆåŠŸ'}")
        
        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯è­¦å‘Šã®èª¬æ˜
        print("\nğŸ“ æ³¨æ„: ã‚¹ã‚¯ãƒªãƒ—ãƒˆçµ‚äº†å¾Œã«ä»¥ä¸‹ã®è­¦å‘ŠãŒè¡¨ç¤ºã•ã‚Œã‚‹å ´åˆãŒã‚ã‚Šã¾ã™:")
        print("   'nrtucode: internal error: XX object(s) leaked, improper teardown'")
        print("   ã“ã‚Œã¯æ­£å¸¸ãªå‹•ä½œã§ã€è¨ˆç®—çµæœã«ã¯å½±éŸ¿ã—ã¾ã›ã‚“ã€‚")
        
    except KeyboardInterrupt:
        print("\nâš¡ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
