# AWS Neuron Hardware Deep Analysis

æœ¬è³‡æ–™ã¯Neuronã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã™ã‚‹ãŸã‚ã®ãƒã‚¦ãƒã‚¦ã«ã¤ã„ã¦æ•´ç†ã—ã¾ã™ã€‚

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰

### Step 1: ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ

```bash
# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã« chown ã—ã¦ãã ã•ã„ã€‚ä¸è¶³ã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
sudo chown -R $USER:$USER /opt/aws_neuronx_venv_pytorch_2_8/lib/python3.10/site-packages/

source /opt/aws_neuronx_venv_pytorch_2_8/bin/activate
cd pytorch-neuron
python scripts/neuron_hardware_deep_analyzer.py
```

å®Ÿè¡Œçµæœã¨ã—ã¦ã€pftraceã¨ã„ã†æ‹¡å¼µå­ã§Neuron Profilerã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«çµæœã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚
`/tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/perfetto_pattern_mapping.json` ã«ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒã‚ã‚Šã€
æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ƒã« pftrace ã®ãƒ‘ã‚¹ã‚’ç†è§£ã—ã¾ã™ã€‚

```bash
...
ğŸ¨ Perfetto analysis files:
   â€¢ /tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/vmap_hardware_deep_hardware.pftrace
   â€¢ /tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/scan_hardware_deep_hardware.pftrace
   â€¢ /tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/for_loop_hardware_small_hardware.pftrace
   â€¢ /tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/for_loop_hardware_medium_hardware.pftrace
   â€¢ /tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/for_loop_hardware_large_hardware.pftrace
   â†’ View at: https://ui.perfetto.dev/
```

### Step 2: Perfettoãƒˆãƒ¬ãƒ¼ã‚¹åˆ†æ

Step 1 ã§ç”Ÿæˆã•ã‚ŒãŸ `perfetto_pattern_mapping.json` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…ƒã« pftrace ã‚’è§£æã—ã¾ã™ã€‚

```bash
uv run scripts/perfetto_analyzer.py
```

å®Ÿè¡Œçµæœã¨ã—ã¦ã€pftraceã«å¯¾ã™ã‚‹SQLã‚¯ã‚¨ãƒªã§ã®è§£æçµæœãŒjsonã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã™ã€‚è‡ªèº«ã§ã‚¯ã‚¨ãƒªã‚’ä¿®æ­£ã—ã¦å¤šæ§˜ãªåˆ†æã‚’ã—ã¦ã‚‚ã‚‰ãˆã¾ã™ã€‚
prefetto-mcp ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åˆ©ç”¨ã™ã‚‹ã¨ prefetto ã® SQL ã‚’è‡ªå‹•ç”Ÿæˆã—ã¦åˆ©ç”¨ã™ã‚‹MCPã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚
`scrips/setup_perfetto_mcp.sh`ã«ä¸€ä¾‹ã¨ã—ã¦Clineã«MCPã‚’è¨­å®šã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”¨æ„ã—ã¾ã—ãŸã€‚ã”è‡ªèº«ã®ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«åˆã‚ã›ã¦MCPè¨­å®šã™ã‚Œã°å‹•ãã¾ã™ã€‚

```bash
...
ğŸ’¾ Results saved to: /tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/vmap_hardware_deep_hardware.pftrace_analysis_comprehensive.json
```

## æ‰‹å…ƒã®å®Ÿè¡Œçµæœ

vmapã¯TensorMatrix Engineã€ã¤ã¾ã‚Šã‚·ã‚¹ãƒˆãƒªãƒƒã‚¯ã‚¢ãƒ¬ã‚¤ã‚’æœ€ã‚‚åŠ¹æœçš„ã«åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚
å°è¦æ¨¡ãªæ§‹é€ ã§ã¯ã‚ã¾ã‚Šforã¨ã®å·®åˆ†ã¯è¦‹ãˆã¦ã“ãªã„ãŒå¤§è¦æ¨¡ãªæ§‹é€ ã«ãªã‚‹ã¨æ€§èƒ½å·®ãŒç¾ã‚Œã¦ãã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚
scanã¯vmapã«æ¬¡ã„ã§ã‚·ã‚¹ãƒˆãƒªãƒƒã‚¯ã‚¢ãƒ¬ã‚¤ã®åˆ©ç”¨åŠ¹ç‡ãŒè‰¯ãå®Ÿåˆ©ç”¨æ™‚ã«ã‚‚å•é¡Œãªãåˆ©ç”¨ã§ãã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚
ã‚ãã¾ã§ä»Šå›ã®è¨ˆæ¸¬çµæœã§ã®çŠ¶æ³ã§ã‚ã‚Šå®Ÿéš›ã®å®Ÿè¡Œæ™‚é–“ã¯å®Ÿè£…ã‚„ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®æ§‹æˆç­‰ã«ã‚ˆã£ã¦å¤§ããç•°ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ãŸã‚åŸºæœ¬çš„ã«ã¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ã‚’ç”¨ã„ãŸè¨ˆæ¸¬ã‚’å®Ÿã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦å®Ÿæ–½ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã‚Œã‚‹ã€‚

```bash
STATISTICAL FINDINGS:
  vmap: Otheræ“ä½œ 15å›, 0.000794ms
  vmap: TensorMatrixæ“ä½œ 5å›, 0.001ms
  scan: WRITEæ“ä½œ 33å›, Otheræ“ä½œæ™‚é–“ 0.002ms
  for-loop: unknownæ“ä½œç¯„å›² 64-1299å€‹
  for-loop scaling: for_loop_small(1117slices) to for_loop_large(10223slices)

STATISTICAL INSIGHTS:
  Analysis condition: all patterns use 3 iterations x 32 batch x 128 features
  Fastest pattern: vmap (total engine time: 0.002ms)
  Slowest pattern: for_loop_large (total engine time: 0.128ms)
  Time difference: 0.126ms, Ratio: 56.8x (calculation: 0.128 / 0.002)
  vmap: TensorMatrix ratio 64.8% (calculation: 0.001 / 0.002 * 100)
  scan: TensorMatrix ratio 45.8% (calculation: 0.002 / 0.004 * 100)
  for_loop_small: TensorMatrix ratio 43.4% (calculation: 0.002 / 0.004 * 100)
  for_loop_medium: TensorMatrix ratio 15.2% (calculation: 0.006 / 0.038 * 100)
  for_loop_large: TensorMatrix ratio 13.4% (calculation: 0.017 / 0.128 * 100)

DATA COMPARISON METRICS TABLE:
Pattern              Total Slices TensorMatrix ms Other ms   Rank  
--------------------------------------------------------------------
vmap                 877          0.001           0.001      5     
scan                 1009         0.002           0.002      3     
for_loop_small       1117         0.002           0.002      4     
for_loop_medium      3401         0.006           0.032      2     
for_loop_large       10223        0.017           0.111      1     
```

# AWS Neuron Hardware Deep Analyzer

AWS Neuron Profiler 2.0ã¨PyTorch/XLAã®æŠ€è¡“èª¿æŸ»ã‚’è¸ã¾ãˆã¦ã€ã‚³ãƒ¼ãƒ‰ã®è©³ç´°ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ¯ ã“ã®ã‚³ãƒ¼ãƒ‰ã®ç›®çš„

AWS Neuronï¼ˆæ©Ÿæ¢°å­¦ç¿’å°‚ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ï¼‰ä¸Šã§ã€**3ã¤ã®ä¸¦åˆ—å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã§ã®æŒ™å‹•ã‚’æ¯”è¼ƒ**ã—ã¾ã™ã€‚

1. **vmap** - PyTorchã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒãƒƒãƒ—ï¼ˆä¸¦åˆ—ãƒãƒƒãƒå‡¦ç†ï¼‰
2. **scan** - é †æ¬¡å‡¦ç†ã®æœ€é©åŒ–ï¼ˆXLA whileã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
3. **for-loop** - é€šå¸¸ã®Pythonãƒ«ãƒ¼ãƒ—

## ğŸ“Š å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "Pythonå®Ÿè¡Œå±¤"
        A[mainé–¢æ•°] --> B[NeuronHardwareProfiler]
        B --> C[vmap/scan/for-loopå®Ÿè¡Œ]
    end
    
    subgraph "ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å±¤"
        C --> D[Neuron Profiler 2.0]
        D --> E[System Profile]
        D --> F[Device Profile]
    end
    
    subgraph "ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢å±¤"
        E --> G[NeuronCoreå®Ÿè¡Œ]
        F --> G
        G --> H[Tensor Engine]
        G --> I[Vector Engine]
        G --> J[Scalar Engine]
        G --> K[GPSIMD Engine]
        G --> L[HBM/SRAM Memory]
    end
    
    subgraph "å‡ºåŠ›å±¤"
        F --> M[NTFF Files]
        E --> N[System Trace]
        M --> O[neuron-profile CLIè§£æ]
        O --> P[JSON Report]
        O --> Q[Perfetto Visualization]
    end
    
    style G fill:#f96,stroke:#333,stroke-width:4px
    style M fill:#9cf,stroke:#333,stroke-width:2px
    style Q fill:#9f6,stroke:#333,stroke-width:2px
```

## ğŸ”¬ ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è©³ç´°è§£èª¬

### 1ï¸âƒ£ **ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹: HardwareProfile**

```python
@dataclass
class HardwareProfile:
    pattern_name: str
    
    # Compute Engineåˆ†æ
    tensor_engine_utilization: float
    vector_engine_utilization: float
    scalar_engine_utilization: float
    gpsimd_engine_utilization: float
    engine_overlap_efficiency: float
    
    # Memory Architectureåˆ†æ
    hbm_bandwidth_utilization: float
    sram_usage_efficiency: float
    dma_transfer_count: int
    memory_bound_score: float
    
    # ... (çœç•¥)
```

**ç›®çš„**: AWS Neuronãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æ§‹é€ åŒ–

**é‡è¦ãªæ¦‚å¿µ**:

- **Compute Engines**: 
  - **Tensor Engine**: è¡Œåˆ—æ¼”ç®—å°‚ç”¨ï¼ˆMATMULç­‰ï¼‰
  - **Vector Engine**: ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ï¼ˆè¦ç´ ã”ã¨ã®åŠ ç®—ã€ReLUç­‰ï¼‰
  - **Scalar Engine**: ã‚¹ã‚«ãƒ©ãƒ¼æ¼”ç®—ï¼ˆå®šæ•°åŠ ç®—ç­‰ï¼‰
  - **GPSIMD Engine**: æ±ç”¨SIMDæ¼”ç®—

- **Memory Architecture**:
  - **HBM (High Bandwidth Memory)**: å¤–éƒ¨é«˜é€Ÿãƒ¡ãƒ¢ãƒª
  - **SRAM**: ã‚ªãƒ³ãƒãƒƒãƒ—ã‚­ãƒ£ãƒƒã‚·ãƒ¥
  - **DMA Transfer**: HBMâ†”SRAMé–“ã®ãƒ‡ãƒ¼ã‚¿è»¢é€

```mermaid
graph LR
    subgraph "NeuronCoreå†…éƒ¨"
        A[Tensor Engine] --> E[SRAM]
        B[Vector Engine] --> E
        C[Scalar Engine] --> E
        D[GPSIMD Engine] --> E
        E <-->|DMA| F[HBM Memory]
    end
    
    style E fill:#ff9,stroke:#333,stroke-width:2px
    style F fill:#9cf,stroke:#333,stroke-width:2px
```

---

### 2ï¸âƒ£ **NeuronHardwareProfiler ã‚¯ãƒ©ã‚¹ - åˆæœŸåŒ–**

```python
class NeuronHardwareProfiler:
    UNIFIED_CONDITIONS = {
        'iterations': 3,           # ã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§3å›å‡¦ç†
        'batch_size': 32,         # ãƒãƒƒãƒã‚µã‚¤ã‚º32
        'feature_size': 128,      # ç‰¹å¾´æ¬¡å…ƒ128
        'model_type': 'small'     # smallãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
    }
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ**: **çµ±ä¸€æ¡ä»¶ï¼ˆUNIFIED_CONDITIONSï¼‰**ã«ã‚ˆã‚Šã€vmap/scan/for-loopã®**å…¬å¹³ãªæ¯”è¼ƒ**ã‚’ä¿è¨¼

**ãªãœçµ±ä¸€æ¡ä»¶ãŒå¿…è¦ã‹**:
- ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚„ãƒ«ãƒ¼ãƒ—å›æ•°ãŒç•°ãªã‚‹ã¨ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ©ç”¨ç‡ãŒå¤§ããå¤‰ã‚ã‚‹
- åŒã˜æ¡ä»¶ã§æ¯”è¼ƒã—ãªã„ã¨ã€ãƒ‘ã‚¿ãƒ¼ãƒ³é–“ã®æœ¬è³ªçš„ãªå·®ãŒè¦‹ãˆãªã„

```python
def __init__(self, analysis_name: str = "hardware_deep_analysis"):
    self.device = torch_xla.device()  # XLAãƒ‡ãƒã‚¤ã‚¹å–å¾—
    self.profile_output_dir = Path(f"/tmp/neuron_hardware_profiles_{analysis_name}")
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³åã¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¿½è·¡
    self.pattern_profile_mapping = {}
    self.profile_execution_order = []
    
    # Neuron Profiler 2.0ç’°å¢ƒè¨­å®š
    os.environ['NEURON_RT_INSPECT_OUTPUT_DIR'] = str(self.profile_output_dir)
```

**ãƒãƒƒãƒ”ãƒ³ã‚°è¿½è·¡ã®ç†ç”±**: Neuron Profilerã¯è¤‡æ•°ã®NTFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã€ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œã™ã‚‹ã‹è¨˜éŒ²ãŒå¿…è¦

### 3ï¸âƒ£ **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ**

```python
@contextmanager
def hardware_profiling_context(self, pattern_name: str):
    """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
    before_files = set(self.profile_output_dir.glob("**/*.ntff"))
    
    try:
        # Neuron Profiler 2.0: System + Device profiles
        with profiler.profile(
            port=9012,
            profile_type='system',  # ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
            target='neuron_profile_perfetto',  # Perfettoçµ±åˆ
            output_dir=str(self.profile_output_dir),
            ms_duration=30000  # 30ç§’é–“ã‚­ãƒ£ãƒ—ãƒãƒ£
        ) as prof:
            os.environ['NEURON_RT_INSPECT_DEVICE_PROFILE'] = '1'
            yield prof
    finally:
        # ç”Ÿæˆã•ã‚ŒãŸNTFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³åã¨ãƒãƒƒãƒ”ãƒ³ã‚°
        after_files = set(self.profile_output_dir.glob("**/*.ntff"))
        new_files = after_files - before_files
        
        for ntff_file in new_files:
            self.pattern_profile_mapping[str(ntff_file)] = pattern_name
            self.profile_execution_order.append((pattern_name, str(ntff_file)))
```

**Neuron Profiler 2.0ã®ä»•çµ„ã¿**:

```mermaid
sequenceDiagram
    participant Code as Pythonã‚³ãƒ¼ãƒ‰
    participant Profiler as Neuron Profiler 2.0
    participant Runtime as Neuron Runtime
    participant Hardware as NeuronCore
    participant NTFF as NTFFãƒ•ã‚¡ã‚¤ãƒ«
    
    Code->>Profiler: profiler.profile() é–‹å§‹
    Profiler->>Runtime: System Profileæœ‰åŠ¹åŒ–
    Profiler->>Hardware: Device Profileæœ‰åŠ¹åŒ–
    
    Code->>Hardware: vmap/scan/for-loopå®Ÿè¡Œ
    
    Hardware->>Hardware: å‘½ä»¤å®Ÿè¡Œ
    Hardware->>Profiler: å‘½ä»¤ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¨˜éŒ²
    Hardware->>Profiler: DMAæ´»å‹•è¨˜éŒ²
    Hardware->>Profiler: ã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨ç‡è¨˜éŒ²
    
    Runtime->>Profiler: APIå‘¼ã³å‡ºã—ãƒˆãƒ¬ãƒ¼ã‚¹
    
    Profiler->>NTFF: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿<br/>(ãƒã‚¤ãƒŠãƒªå½¢å¼)
    
    Code->>Profiler: profiler.profile() çµ‚äº†
    NTFF->>Code: NTFFãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¿”å´
```

**NTFF (Neuron Trace File Format)** ã¨ã¯

- ãƒã‚¤ãƒŠãƒªå½¢å¼ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‡ãƒ¼ã‚¿
- å‘½ä»¤ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ï¼ˆãƒŠãƒç§’ç²¾åº¦ï¼‰
- DMAè»¢é€ãƒ‘ã‚¿ãƒ¼ãƒ³
- ã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨çŠ¶æ³
- ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³

---

### 4ï¸âƒ£ **vmap ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æ**

```python
def analyze_vmap_hardware_behavior(self, data: torch.Tensor) -> HardwareProfile:
    """vmapå†…éƒ¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æï¼ˆçµ±ä¸€æ¡ä»¶ï¼‰"""
    
    with self.hardware_profiling_context("vmap_hardware_deep"):
        def vector_operation(x):
            # è¤‡æ•°ã®æ¼”ç®—ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ©ç”¨ã‚’è¦³å¯Ÿ
            result = torch.sum(x * x, dim=-1)  # Tensor Engine
            result = torch.relu(result)        # Vector Engine  
            result = result + 0.1              # Scalar Engine
            return result
            
        # çµ±ä¸€æ¡ä»¶ï¼š3å›ã®ãƒãƒƒãƒå‡¦ç†
        batch_input = data.unsqueeze(0).repeat(self.UNIFIED_CONDITIONS['iterations'], 1, 1)
        vmapped_result = torch.vmap(vector_operation)(batch_input)
        torch_xla.sync()
```

**vmapã®å‹•ä½œåŸç†**

```mermaid
graph TB
    subgraph "vmapå¤‰æ›å‰"
        A[ãƒ‡ãƒ¼ã‚¿: batch_size x features] --> B[for i in range batch]
        B --> C[vector_operationå˜ä¸€ã‚µãƒ³ãƒ—ãƒ«]
        C --> D[çµæœã‚’stack]
    end
    
    subgraph "vmapå¤‰æ›å¾Œ - PyTorchãŒè‡ªå‹•æœ€é©åŒ–"
        E[ãƒ‡ãƒ¼ã‚¿: batch_size x features] --> F[torch.vmap]
        F --> G[ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸæ¼”ç®—]
        G --> H[ä¸¦åˆ—å®Ÿè¡Œon NeuronCore]
    end
    
    style G fill:#9f6,stroke:#333,stroke-width:3px
    style H fill:#f96,stroke:#333,stroke-width:3px
```

**vmapã®ç‰¹å¾´**

- **è‡ªå‹•ãƒ™ã‚¯ãƒˆãƒ«åŒ–**: for-loopã‚’PyTorchå†…éƒ¨ã§ä¸¦åˆ—åŒ–
- **ãƒãƒƒãƒãƒ‡ã‚£ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³å‡¦ç†**: æ˜ç¤ºçš„ãªãƒ«ãƒ¼ãƒ—ãªã—ã§ãƒãƒƒãƒå‡¦ç†
- **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–**: NeuronCoreä¸Šã§åŠ¹ç‡çš„ã«ä¸¦åˆ—å®Ÿè¡Œ

### 5ï¸âƒ£ **scan ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æ**

```python
def analyze_scan_hardware_behavior(self, data: torch.Tensor) -> HardwareProfile:
    """scanå†…éƒ¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æï¼ˆçµ±ä¸€æ¡ä»¶ï¼‰"""
    
    with self.hardware_profiling_context("scan_hardware_deep"):
        if TORCH_FUNC_AVAILABLE:
            def scan_function(carry, x):
                # Sequential computationã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³è¦³å¯Ÿ
                new_carry = carry + torch.sum(x)  # Memory access pattern
                intermediate = torch.matmul(x, x.T)  # Tensor Engine utilization
                return new_carry, new_carry + torch.sum(intermediate)
            
            init_carry = torch.tensor(0.0, device=self.device)
            # çµ±ä¸€æ¡ä»¶ï¼š3å›ã®é †æ¬¡å‡¦ç†
            scan_inputs = data.unsqueeze(0).repeat(self.UNIFIED_CONDITIONS['iterations'], 1, 1)
            final_carry, outputs = torch.func.scan(scan_function, init_carry, scan_inputs)
        
        torch_xla.sync()
```

**scanã®å‹•ä½œåŸç†**

```mermaid
graph TB
    subgraph "é€šå¸¸ã®for-loop"
        A1[iteration 0] --> A2[iteration 1] --> A3[iteration 2]
        A1 --> B1[HLOã‚°ãƒ©ãƒ•ã«å±•é–‹]
        A2 --> B1
        A3 --> B1
        B1 --> C1[é•·å¤§ãªã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“]
    end
    
    subgraph "torch.func.scan - XLAæœ€é©åŒ–"
        D1[scan function] --> D2[XLA while operation]
        D2 --> D3[1å›ã ã‘ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«]
        D3 --> D4[ãƒ«ãƒ¼ãƒ—ã‚’ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§å®Ÿè¡Œ]
    end
    
    style D2 fill:#9cf,stroke:#333,stroke-width:3px
    style D4 fill:#f96,stroke:#333,stroke-width:3px
```

**scanã®ç‰¹å¾´**

- **XLA while operation**: ãƒ«ãƒ¼ãƒ—è‡ªä½“ãŒã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã®ä¸€ç´šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
- **ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚é–“çŸ­ç¸®**: 1å›ã®åå¾©ã ã‘ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã€æ®‹ã‚Šã¯å®Ÿè¡Œæ™‚ã«ãƒ«ãƒ¼ãƒ—
- **çŠ¶æ…‹ã®æŒã¡è¶Šã—**: `carry`ã§åå¾©é–“ã§çŠ¶æ…‹ã‚’åŠ¹ç‡çš„ã«ä¼æ¬

# AWS Neuron Hardware Deep Analyzer

## 6ï¸âƒ£ **for-loop ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æ**

```python
def analyze_for_loop_hardware_behavior(self, data: torch.Tensor, loop_size: str = "medium") -> HardwareProfile:
    """for-loopå†…éƒ¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æï¼ˆçµ±ä¸€æ¡ä»¶ãƒ»TEN404ã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆï¼‰"""
    
    try:
        with self.hardware_profiling_context(f"for_loop_hardware_{loop_size}"):
            # TEN404å›é¿ã®ãŸã‚å˜ç´”åŒ–ã—ãŸloopæ§‹é€ ï¼ˆçµ±ä¸€æ¡ä»¶ä½¿ç”¨ï¼‰
            result = torch.zeros(data.size(1), device=self.device)
            
            # çµ±ä¸€æ¡ä»¶ï¼š3å›ã®ãƒ«ãƒ¼ãƒ—å‡¦ç†
            for i in range(self.UNIFIED_CONDITIONS['iterations']):
                # å˜ç´”åŒ–ã•ã‚ŒãŸoperationsï¼ˆTEN404å›é¿ï¼‰
                idx = i % data.size(0)
                processed = torch.mean(data[idx])  # å˜ç´”ãªreduction
                result = result + processed
                
            torch_xla.sync()
    except Exception as e:
        # ã•ã‚‰ã«å˜ç´”åŒ–ã—ãŸãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        with self.hardware_profiling_context(f"for_loop_hardware_{loop_size}_simple"):
            result = torch.tensor(0.0, device=self.device)
            for i in range(self.UNIFIED_CONDITIONS['iterations']):
                idx = i % data.size(0)
                result = result + torch.sum(data[idx])
            torch_xla.sync()
```

**TEN404ã‚¨ãƒ©ãƒ¼ã¨ã¯**: XLAï¼ˆAccelerated Linear Algebraï¼‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒè¤‡é›‘ã™ãã‚‹æ¼”ç®—ã‚°ãƒ©ãƒ•ã‚’å‡¦ç†ã§ããªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼

**3ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ**

```mermaid
graph TB
    subgraph "vmap - å®Œå…¨ä¸¦åˆ—"
        A1[ãƒãƒƒãƒå…¨ä½“] --> A2[è‡ªå‹•ãƒ™ã‚¯ãƒˆãƒ«åŒ–]
        A2 --> A3[å…¨Tensor/Vector Engineä¸¦åˆ—åˆ©ç”¨]
        A3 --> A4[é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ]
    end
    
    subgraph "scan - æœ€é©åŒ–é †æ¬¡"
        B1[åå¾©å‡¦ç†] --> B2[XLA while op]
        B2 --> B3[1å›ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«+ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ]
        B3 --> B4[ä¸­ç¨‹åº¦ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ]
    end
    
    subgraph "for-loop - é€šå¸¸é †æ¬¡"
        C1[åå¾©å‡¦ç†] --> C2[Python for-loop]
        C2 --> C3[å„åå¾©ã‚’å€‹åˆ¥ã«å®Ÿè¡Œ]
        C3 --> C4[ä½ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ]
    end
    
    style A3 fill:#9f6,stroke:#333,stroke-width:3px
    style B2 fill:#9cf,stroke:#333,stroke-width:3px
    style C2 fill:#faa,stroke:#333,stroke-width:3px
```

## 7ï¸âƒ£ **NTFFãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã¨ãƒãƒƒãƒ”ãƒ³ã‚°**

```python
def _find_ntff_file_for_pattern(self, pattern_name: str) -> Optional[Path]:
    """ãƒ‘ã‚¿ãƒ¼ãƒ³åã«å¯¾å¿œã™ã‚‹NTFFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    
    # 1. execution orderã‹ã‚‰æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    for saved_pattern, ntff_file_path in reversed(self.profile_execution_order):
        if saved_pattern == pattern_name:
            ntff_file = Path(ntff_file_path)
            if ntff_file.exists():
                return ntff_file
    
    # 2. pattern mappingã‹ã‚‰æ¤œç´¢ (é€†å¼•ã)
    for ntff_file_path, saved_pattern in self.pattern_profile_mapping.items():
        if saved_pattern == pattern_name:
            ntff_file = Path(ntff_file_path)
            if ntff_file.exists():
                return ntff_file
    
    # 3. ãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚° (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
    all_ntff_files = list(self.profile_output_dir.glob("**/*.ntff"))
    for ntff_file in all_ntff_files:
        if pattern_name in str(ntff_file.name).lower():
            return ntff_file
    
    return None
```

**ãªãœè¤‡é›‘ãªæ¤œç´¢ãŒå¿…è¦ã‹**

- Neuron Profilerã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨
- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚„ãƒ©ãƒ³ãƒ€ãƒ ãªè­˜åˆ¥å­ãŒå«ã¾ã‚Œã‚‹
- å®Ÿè¡Œé †åºã‚’è¿½è·¡ã—ãªã„ã¨ã€ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹åˆ†ã‹ã‚‰ãªããªã‚‹

## 8ï¸âƒ£ **NTFFè§£æ - neuron-profile CLIä½¿ç”¨**

```python
def _analyze_ntff_with_neuron_profile(self, ntff_path: Path, neff_path: Optional[Path]) -> Dict:
    """neuron-profileãƒ„ãƒ¼ãƒ«ã§NTFFè©³ç´°è§£æ"""
    
    try:
        cmd_args = [
            'neuron-profile', 'view',
            '--output-format', 'json',
            '--output-file', '/tmp/profile_analysis.json'
        ]
        
        if neff_path and neff_path.exists():
            cmd_args.extend(['-n', str(neff_path)])
        cmd_args.extend(['-s', str(ntff_path)])
        
        result = subprocess.run(cmd_args, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            with open('/tmp/profile_analysis.json', 'r') as f:
                profile_data = json.load(f)
            return self._process_profile_json(profile_data)
    except Exception as e:
        self.logger.error(f"NTFF analysis failed: {e}")
    
    return {}
```

**neuron-profile CLIã®å½¹å‰²**

```mermaid
sequenceDiagram
    participant Python as Pythonã‚³ãƒ¼ãƒ‰
    participant CLI as neuron-profile CLI
    participant NTFF as NTFFãƒ•ã‚¡ã‚¤ãƒ«<br/>(ãƒã‚¤ãƒŠãƒª)
    participant NEFF as NEFFãƒ•ã‚¡ã‚¤ãƒ«<br/>(ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿)
    participant JSON as JSONå‡ºåŠ›
    
    Python->>CLI: neuron-profile view --output-format json
    CLI->>NTFF: ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    CLI->>NEFF: ãƒ‡ãƒãƒƒã‚°ã‚·ãƒ³ãƒœãƒ«èª­ã¿è¾¼ã¿
    
    CLI->>CLI: å‘½ä»¤ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è§£æ
    CLI->>CLI: ã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨ç‡è¨ˆç®—
    CLI->>CLI: DMAè»¢é€ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
    CLI->>CLI: ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹è§£æ
    
    CLI->>JSON: æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
    JSON->>Python: è§£æçµæœè¿”å´
```

**neuron-profile CLIãŒæä¾›ã™ã‚‹æƒ…å ±**
- **Summary**: å®Ÿè¡Œæ™‚é–“ã€ã‚¤ãƒ™ãƒ³ãƒˆæ•°ã€ã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨ç‡
- **Instruction**: å„å‘½ä»¤ã®è©³ç´°ï¼ˆopcodeã€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã€æœŸé–“ï¼‰
- **DMA Activity**: ãƒ¡ãƒ¢ãƒªè»¢é€ãƒ‘ã‚¿ãƒ¼ãƒ³
- **Engine Utilization**: Tensor/Vector/Scalar/GPSIMDã‚¨ãƒ³ã‚¸ãƒ³ã®åˆ©ç”¨ç‡

---

## 9ï¸âƒ£ **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«JSONå‡¦ç†ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º**

```python
def _process_profile_json(self, profile_data: Dict) -> Dict:
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«JSONãƒ‡ãƒ¼ã‚¿å‡¦ç†"""
    processed = {}
    
    # Summaryæƒ…å ±æŠ½å‡º
    if 'summary' in profile_data:
        summary = profile_data['summary'][0]
        processed['hardware_execution_time_ns'] = int(summary.get('total_time', 0) * 1_000_000_000)
        processed['total_instructions'] = summary.get('event_count', 0)
        
        # Engine utilization
        processed['tensor_engine_util'] = summary.get('tensor_utilization', 0.0)
        processed['vector_engine_util'] = summary.get('vector_utilization', 0.0)
    
    # Instructionåˆ†æ
    if 'instruction' in profile_data:
        instructions = profile_data['instruction']
        instruction_categories = {}
        
        for instr in instructions:
            opcode = instr.get('opcode', 'unknown')
            instruction_categories[opcode] = instruction_categories.get(opcode, 0) + 1
        
        processed['instruction_categories'] = instruction_categories
        
        # Memory vs Compute boundåˆ¤å®š
        memory_ops = sum(count for op, count in instruction_categories.items() 
                       if any(mem_op in op.lower() for mem_op in ['load', 'store', 'dma', 'copy']))
        compute_ops = sum(count for op, count in instruction_categories.items()
                        if any(comp_op in op.lower() for comp_op in ['matmul', 'add', 'mul', 'conv']))
        
        total_ops = memory_ops + compute_ops
        if total_ops > 0:
            processed['memory_bound_score'] = memory_ops / total_ops
            processed['compute_bound_score'] = compute_ops / total_ops
    
    return processed
```

**Memory Bound vs Compute Boundåˆ¤å®š**

```mermaid
graph LR
    subgraph "å‘½ä»¤åˆ†é¡"
        A[å…¨å‘½ä»¤] --> B{å‘½ä»¤ã‚¿ã‚¤ãƒ—}
        B -->|load/store/dma| C[Memoryæ“ä½œ]
        B -->|matmul/add/mul| D[Computeæ“ä½œ]
    end
    
    subgraph "åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯"
        C --> E[memory_ops count]
        D --> F[compute_ops count]
        E --> G{memory_ops > 70%?}
        F --> G
        G -->|Yes| H[Memory Bound]
        G -->|No| I{compute_ops > 70%?}
        I -->|Yes| J[Compute Bound]
        I -->|No| K[Balanced]
    end
    
    style H fill:#faa,stroke:#333,stroke-width:3px
    style J fill:#afa,stroke:#333,stroke-width:3px
    style K fill:#aaf,stroke:#333,stroke-width:3px
```

**æœ€é©åŒ–ã®æ–¹å‘æ€§**

- **Memory Bound**: HBMâ†”SRAMè»¢é€æœ€é©åŒ–ã€ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ”¹å–„
- **Compute Bound**: ã‚¨ãƒ³ã‚¸ãƒ³ä¸¦åˆ—åŒ–ã€æ¼”ç®—èåˆï¼ˆoperation fusionï¼‰

## ğŸ”Ÿ **æœ€é©åŒ–æ¨å¥¨ç”Ÿæˆ**

```python
def _generate_optimization_recommendations(self, analysis: Dict) -> List[str]:
    """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æã«åŸºã¥ãæœ€é©åŒ–æ¨å¥¨"""
    recommendations = []
    
    memory_bound_score = analysis.get('memory_bound_score', 0)
    if memory_bound_score > 0.7:
        recommendations.append("Memory-bound: HBMâ†”SRAM transfer optimization required")
        recommendations.append("Consider data layout optimization for better cache locality")
        
    compute_bound_score = analysis.get('compute_bound_score', 0)  
    if compute_bound_score > 0.7:
        recommendations.append("Compute-bound: Engine parallelization optimization required")
        recommendations.append("Consider operation fusion for better hardware utilization")
        
    tensor_util = analysis.get('tensor_engine_util', 0)
    if tensor_util < 0.5:
        recommendations.append("Low Tensor Engine utilization: Consider matrix operation optimization")
        
    return recommendations
```

## 1ï¸âƒ£1ï¸âƒ£ **Perfettoå¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ**

```python
def generate_perfetto_analysis(self) -> List[str]:
    """Perfettoçµ±åˆè§£æå®Ÿè¡Œï¼ˆæ„å‘³ã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åä»˜ãï¼‰"""
    
    perfetto_files = []
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³åé †åºã«å¾“ã£ã¦Perfettoãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    for pattern_name, ntff_file_path in self.profile_execution_order:
        ntff_file = Path(ntff_file_path)
        
        # æ„å‘³ã®ã‚ã‚‹Perfettoãƒ•ã‚¡ã‚¤ãƒ«å
        perfetto_filename = f"{pattern_name}_hardware.pftrace"
        perfetto_output = self.profile_output_dir / perfetto_filename
        
        cmd_args = [
            'neuron-profile', 'view',
            '--output-format', 'perfetto',
            '--output-file', str(perfetto_output),
            '-n', str(neff_file),
            '-s', str(ntff_file)
        ]
        
        result = subprocess.run(cmd_args, capture_output=True, text=True, timeout=120)
        
        if result.returncode == 0:
            perfetto_files.append(str(perfetto_output))
    
    return perfetto_files
```

**Perfettoã¨ã¯**:
- Googleè£½ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¹å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«
- https://ui.perfetto.dev/ ã§ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§é–²è¦§å¯èƒ½
- ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å½¢å¼ã§ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚¤ãƒ™ãƒ³ãƒˆã‚’å¯è¦–åŒ–

```mermaid
graph LR
    A[NTFF File] --> B[neuron-profile CLI]
    B --> C[.pftrace File]
    C --> D[Perfetto UI]
    D --> E[ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³]
    
    subgraph "Perfetto UIã§è¦‹ã‚Œã‚‹æƒ…å ±"
        E --> F[å‘½ä»¤å®Ÿè¡Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³]
        E --> G[ã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨çŠ¶æ³]
        E --> H[DMAè»¢é€ãƒ‘ã‚¿ãƒ¼ãƒ³]
        E --> I[ãƒœãƒˆãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–]
    end
    
    style D fill:#9f6,stroke:#333,stroke-width:3px
```

## 1ï¸âƒ£2ï¸âƒ£ **ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼å…¨ä½“**

```python
def main():
    """ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ·±å±¤è§£æãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    # 1. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼åˆæœŸåŒ–
    analyzer = NeuronHardwareProfiler("comprehensive_hardware_deep_analysis")
    
    # 2. åŒ…æ‹¬çš„ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æŒ™å‹•è§£æ
    hardware_profiles = analyzer.run_comprehensive_hardware_analysis()
    
    # 3. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_file = analyzer.generate_hardware_analysis_report(hardware_profiles)
    
    # 4. Perfettoçµ±åˆè§£æ
    perfetto_files = analyzer.generate_perfetto_analysis()
    
    # 5. çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print(f"ğŸ“Š Detailed report: {report_file}")
    print(f"ğŸ¨ Perfetto files: {perfetto_files}")
```

**å®Œå…¨ãªå®Ÿè¡Œãƒ•ãƒ­ãƒ¼**

```mermaid
graph TB
    A[mainé–¢æ•°é–‹å§‹] --> B[NeuronHardwareProfileråˆæœŸåŒ–]
    
    B --> C[çµ±ä¸€æ¡ä»¶ã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ<br/>batch_size=32, features=128]
    
    C --> D[vmapè§£æå®Ÿè¡Œ]
    C --> E[scanè§£æå®Ÿè¡Œ]
    C --> F[for-loopè§£æå®Ÿè¡Œ]
    
    D --> G[Neuron Profiler 2.0<br/>ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°]
    E --> G
    F --> G
    
    G --> H[NTFFç”Ÿæˆ<br/>device+system profiles]
    
    H --> I[neuron-profile CLI<br/>JSONè§£æ]
    
    I --> J[HardwareProfileæ§‹ç¯‰<br/>ã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨ç‡/ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç­‰]
    
    J --> K[æœ€é©åŒ–æ¨å¥¨ç”Ÿæˆ<br/>Memory/Compute boundåˆ¤å®š]
    
    K --> L[JSONãƒ¬ãƒãƒ¼ãƒˆä¿å­˜]
    K --> M[Perfettoå¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ]
    
    L --> N[ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚µãƒãƒªãƒ¼è¡¨ç¤º]
    M --> N
    
    N --> O[è§£æå®Œäº†]
    
    style G fill:#f96,stroke:#333,stroke-width:4px
    style J fill:#9cf,stroke:#333,stroke-width:3px
    style M fill:#9f6,stroke:#333,stroke-width:3px
```

## ğŸ¯ **ã¾ã¨ã‚**

1. **vmap vs scan vs for-loop**ã®**ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ¬ãƒ™ãƒ«ã§ã®å†…éƒ¨å‹•ä½œã®é•ã„**
2. å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®**Compute Engineåˆ©ç”¨åŠ¹ç‡**ï¼ˆTensor/Vector/Scalar/GPSIMDï¼‰
3. **Memory Architecture**ã®ä½¿ã‚ã‚Œæ–¹ï¼ˆHBM/SRAM/DMAè»¢é€ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
4. **ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š**ï¼ˆMemory Bound or Compute Boundï¼‰
5. **æœ€é©åŒ–ã®æ–¹å‘æ€§**ï¼ˆå…·ä½“çš„ãªæ¨å¥¨äº‹é …ï¼‰

**å‡ºåŠ›ã•ã‚Œã‚‹æˆæœç‰©**:
- **JSON Report**: å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- **Perfetto Files**: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å¯è¦–åŒ–
- **Optimization Recommendations**: ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è§£æã«åŸºã¥ãæ”¹å–„ææ¡ˆ

## Perfettoãƒˆãƒ¬ãƒ¼ã‚¹
**å‚è€ƒæ–‡çŒ®**

- [Getting Started with Model Profiling on AWS Trainium & Inferentia Using AWS Neuron Profiler](https://builder.aws.com/content/33FrJL2E97pPBNrqmYmvCRIHMew)
- [Decoding NKI Kernel Performance using AWS Neuron Profiler](https://builder.aws.com/content/34Ru44lIq9QrlPgr16BvDm78F3G)

### Perfettoãƒˆãƒ¬ãƒ¼ã‚¹ç”¨èªé›†

#### **åŸºæœ¬ç”¨èª**

| ç”¨èª | æ„å‘³ | å®Ÿä¾‹ |
|------|------|------|
| **Slice** | å®Ÿè¡Œã•ã‚ŒãŸå€‹åˆ¥æ“ä½œã®æ™‚é–“åŒºé–“ | `TENSOR_REDUCE`ãŒ0.5mså®Ÿè¡Œã•ã‚ŒãŸåŒºé–“ |
| **unknown** | åˆ†é¡ã•ã‚Œã¦ã„ãªã„æ“ä½œ | ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æœ€é©åŒ–ã§å¤‰æ›ã•ã‚ŒãŸæ“ä½œ |
| **Timeline** | æ™‚é–“è»¸ã«æ²¿ã£ãŸå®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ | çµŒéæ™‚é–“0ç§’ã‹ã‚‰å®Ÿè¡Œçµ‚äº†ã¾ã§ã®æµã‚Œ |
| **Engine** | NeuronCoreã®è¨ˆç®—ãƒ¦ãƒ‹ãƒƒãƒˆ | TensorMatrix, Vector, Scalar, GPSIMD |
| **DMA** | Direct Memory Access | HBMâ†”SRAMé–“ã®ãƒ‡ãƒ¼ã‚¿è»¢é€æ“ä½œ |

#### **NeuronCore v2 ã‚¨ãƒ³ã‚¸ãƒ³**

```
NeuronCore v2 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NeuronCore v2 Compute Engines                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. TensorMatrix Engine                                      â”‚
â”‚    â€¢ MatMul (è¡Œåˆ—ä¹—ç®—)                                       â”‚
â”‚    â€¢ Convolution (ç•³ã¿è¾¼ã¿)                                  â”‚
â”‚    â€¢ LoadStationary (é‡ã¿ãƒ­ãƒ¼ãƒ‰ - ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ)        â”‚
â”‚    â€¢ MultiplyMoving (å®Ÿéš›ã®è¡Œåˆ—æ¼”ç®—)                          â”‚
â”‚                                                             â”‚
â”‚ 2. Vector Engine                                            â”‚
â”‚    â€¢ Element-wise operations (è¦ç´ æ¯æ¼”ç®—)                     â”‚
â”‚    â€¢ ReLU, Sigmoid, Tanh (æ´»æ€§åŒ–é–¢æ•°)                        â”‚
â”‚    â€¢ Add, Multiply (ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—)                            â”‚
â”‚                                                             â”‚
â”‚ 3. Scalar Engine                                            â”‚
â”‚    â€¢ Control flow (åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼)                               â”‚
â”‚    â€¢ Scalar operations (ã‚¹ã‚«ãƒ©ãƒ¼æ¼”ç®—)                         â”‚
â”‚    â€¢ Branch operations (åˆ†å²å‡¦ç†)                            â”‚
â”‚                                                             â”‚
â”‚ 4. GPSIMD Engine                                            â”‚
â”‚    â€¢ SIMD parallel processing (SIMDä¸¦åˆ—å‡¦ç†)                  â”‚
â”‚    â€¢ Broadcast operations (ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ)                  â”‚
â”‚    â€¢ Parallel reductions (ä¸¦åˆ—ãƒªãƒ€ã‚¯ã‚·ãƒ§ãƒ³)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### **å®Ÿè¡Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³æ§‹é€ **

```
Perfettoå®Ÿè¡Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³æ§‹é€  (ä¸Šã‹ã‚‰ä¸‹ã¸):

â”Œâ”€ DMA Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ DMA Throughput (GB/s): ãƒ¡ãƒ¢ãƒªè»¢é€å¸¯åŸŸå¹…                 â”‚
â”‚ â€¢ Pending DMA Count: å¾…æ©Ÿä¸­ãƒ¡ãƒ¢ãƒªè»¢é€æ•°                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†‘ **æœ€é‡è¦**: ãƒ¡ãƒ¢ãƒªãƒã‚¦ãƒ³ãƒ‰åˆ¤å®šã®éµ
          
â”Œâ”€ Memory Transfers & On-Chip SRAM Activity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Input/Output tensor movement (å…¥å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«ç§»å‹•)       â”‚
â”‚ â€¢ Intermediate tensor spilling (ä¸­é–“çµæœæº¢ã‚Œ)            â”‚
â”‚ â€¢ HBM â†” SRAM DMA operations (ãƒ¡ãƒ¢ãƒªéšå±¤é–“è»¢é€)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†‘ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–ã®ãƒã‚¤ãƒ³ãƒˆ

â”Œâ”€ NeuronCore Engine Execution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ TensorMatrix Engine: MatMulå®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³                â”‚
â”‚ â€¢ Vector Engine: Element-wiseå‡¦ç†                       â”‚
â”‚ â€¢ Scalar Engine: åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼å‡¦ç†                          â”‚
â”‚ â€¢ GPSIMD Engine: ä¸¦åˆ—SIMDå‡¦ç†                           â”‚
â”‚ â€¢ CC-core: Collective Compute (åˆ†æ•£å®Ÿè¡ŒåŒæœŸ)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†‘ **ã‚¨ãƒ³ã‚¸ãƒ³é‡è¤‡åŠ¹ç‡**ãŒæ€§èƒ½ã‚’æ±ºå®š

â”Œâ”€ Execution Timeline Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ System-level API calls (ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«API)             â”‚
â”‚ â€¢ Framework function calls (ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–¢æ•°)          â”‚
â”‚ â€¢ Overall execution flow (å…¨ä½“å®Ÿè¡Œãƒ•ãƒ­ãƒ¼)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†‘ é«˜ãƒ¬ãƒ™ãƒ«å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³æŠŠæ¡
```

### è§£ææ‰‹æ³•

#### **1. Engine Utilizationåˆ†æ**

```sql
-- TensorMatrix Engineæ´»ç”¨åº¦
SELECT name, COUNT(*) as count, AVG(dur)/1e6 as avg_ms 
FROM slice 
WHERE name REGEXP 'TENSOR_TENSOR|TENSOR_REDUCE|MATMUL' 
GROUP BY name ORDER BY count DESC;

-- Vector EngineåŠ¹ç‡
SELECT name, COUNT(*) as count, AVG(dur)/1e6 as avg_ms 
FROM slice 
WHERE name REGEXP 'RELU|ADD|MUL|SIGMOID' 
GROUP BY name ORDER BY count DESC;
```

#### **2. DMA Activityåˆ†æ**

```sql
-- DMAè»¢é€ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
SELECT name, COUNT(*) as transfers, SUM(dur)/1e6 as total_ms
FROM slice 
WHERE name IN ('WRITE', 'READ', 'DMA_DIRECT2D', 'COPY')
GROUP BY name ORDER BY total_ms DESC;

-- Memory-boundç‰¹æ€§åˆ¤å®š
SELECT 
  (SELECT SUM(dur) FROM slice WHERE name LIKE '%DMA%') as dma_time,
  (SELECT SUM(dur) FROM slice WHERE name REGEXP 'TENSOR|VECTOR') as compute_time;
```

#### **3. Engine OverlapåŠ¹ç‡æ¸¬å®š**

```sql
-- åŒæ™‚å®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³æ¤œå‡º
SELECT 
  s1.name as engine1, 
  s2.name as engine2,
  COUNT(*) as overlap_count
FROM slice s1, slice s2 
WHERE s1.ts < s2.ts + s2.dur AND s2.ts < s1.ts + s1.dur
  AND s1.name != s2.name
  AND s1.name REGEXP 'TENSOR|VECTOR|SCALAR|GPSIMD'
  AND s2.name REGEXP 'TENSOR|VECTOR|SCALAR|GPSIMD'
GROUP BY s1.name, s2.name;
```

### Perfetto MCPè§£æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹

#### **åŸºæœ¬è§£æ**
```
"Use perfetto trace /tmp/neuron_hardware_profiles_comprehensive_hardware_deep_analysis/vmap_hardware_deep_hardware.pftrace for analysis: Analyze vmap hardware utilization patterns in neuron execution"
```

#### **ãƒ‘ã‚¿ãƒ¼ãƒ³æ¯”è¼ƒ**
```
"Compare vmap vs scan hardware utilization patterns using the respective pftrace files"
```

#### **For-loopã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æ**
```
"Analyze for-loop size scaling performance differences comparing small, medium, and large hardware traces"
```

#### **ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ¤œå‡º**
```
"Find performance bottlenecks in neuron hardware timeline across all patterns"
```